# 10

# 贝叶斯 ML–动态夏普比率和配对交易

在本章中，我们将介绍**机器学习**（**ML**）的贝叶斯方法，以及它们对不确定性的不同观点如何在制定和评估交易策略时增加价值。

贝叶斯统计使我们能够量化未来事件的不确定性，并在新信息到来时以有原则的方式完善我们的估计。这种动态方法很好地适应了金融市场不断变化的性质。当相关数据较少且我们需要系统地整合先前知识或假设的方法时，该方法尤其有用。

我们将看到，机器学习的贝叶斯方法可以更深入地了解统计指标、参数估计和预测的不确定性。应用范围从更精细的风险管理到动态更新预测模型，这些预测模型结合了市场环境的变化。资产配置的 Black-Litterman 方法（参见*第 5 章*、*投资组合优化和绩效评估*可以解释为贝叶斯模型。它将一项资产的预期回报计算为市场均衡和投资者观点的平均值，并通过每项资产的波动性、交叉资产相关性和对每项预测的信心进行加权。

更具体地说，在本章中，我们将介绍：

*   贝叶斯统计在 ML 中的应用
*   基于 PyMC3 的概率规划
*   使用 PyMC3 定义和训练 ML 模型
*   如何使用最先进的抽样方法进行近似推理
*   贝叶斯 ML 应用程序用于计算动态夏普比率、动态对交易对冲比率和估计随机波动率

您可以在 GitHub 存储库的相应目录中找到本章的代码示例以及指向其他资源的链接。笔记本电脑包括图像的彩色版本。

# 贝叶斯机器学习的工作原理

**经典统计学**被称为遵循频率论方法，因为它将概率解释为一个事件在长期内的相对频率，也就是说，在观察了大量试验之后。在概率的上下文中，事件是一个实验的一个或多个基本结果的组合，例如两个骰子掷六个相等的结果中的任何一个，或者给定一天资产价格下跌 10%或更多）。

**贝叶斯统计**相反，将概率视为对事件发生的信心或信念的度量。因此，与频繁解释相比，贝叶斯观点为主观观点和观点差异留下了更多的空间。这种差异在事件发生频率不足以客观衡量长期频率的情况下最为显著。

换言之，频率统计假设数据是来自人群的随机样本，旨在确定生成数据的固定参数。反过来，贝叶斯统计将数据视为给定数据，并将参数视为随机变量，其分布可以从数据中推断出来。因此，频率分析方法需要的数据点至少与需要估计的参数数量相同。另一方面，贝叶斯方法与较小的数据集兼容，非常适合一次从一个样本进行在线学习。

贝叶斯观点对于许多罕见或独特的现实世界事件非常有用，至少在重要方面是如此。例子包括下一次选举的结果或市场是否会在 3 个月内崩溃的问题。在每种情况下，都有相关的历史数据以及随着事件的临近而呈现的独特情况。

我们将首先介绍 Bayes 定理，该定理通过将先验假设与新的经验证据相结合来明确更新信念的概念，并将得到的参数估计与其频繁对应的参数估计进行比较。然后，我们将演示两种贝叶斯统计推断方法，即共轭先验和近似推断，这两种方法可以深入了解潜在（即未观测）参数的后验分布，例如期望值：

*   **共轭先验**通过提供一个封闭形式的解，使我们能够精确计算解，从而促进更新过程。然而，这种精确的分析方法并不总是可用的。
*   **近似推断**模拟假设和数据组合产生的分布，并使用该分布中的样本计算统计洞察。

## 如何根据经验证据更新假设

> “当事实发生变化时，我改变了主意。你是怎么做的，先生？”
> 
> ——约翰·梅纳德·凯恩斯

托马斯贝耶斯牧师在 250 多年前提出的定理，使用基本概率理论来规定概率或信念如何随着相关新信息的到来而改变。前面的凯恩斯语录抓住了这种精神。它依赖于条件概率、全概率和链式规则；参见 Bishop（2006）和 Gelman 等人（2013）的介绍及更多内容。

概率信念涉及单个参数或参数向量![](../Images/Image66193.png)（也称为假设）。每个参数可以是离散的或连续的。![](../Images/B15439_10_003.png)可以是一维统计量，如分类变量的（离散）模式或（连续）平均值，也可以是更高维的值集，如协方差矩阵或深度神经网络的权重。

与频率统计的一个关键区别是，贝叶斯假设表示为概率分布，而不是参数值。因此，当频率论推理集中于点估计时，贝叶斯推理产生概率分布。

Bayes 定理通过从以下输入计算**后验概率分布**来更新有关感兴趣参数的信念，如*图 10.1*所示：

*   先验 T1 分布表明我们考虑每个可能的假设的可能性。
*   **似然函数**输出参数![](../Images/B15439_10_003.png)给定一定值时观察数据集的概率，即针对特定假设。
*   考虑到所有可能的假设，**证据**衡量了观测数据的可能性。因此，它对所有参数值都是相同的，用于规范化分子。

<figure class="mediaobject">![](../Images/B15439_10_01.png)</figure>

图 10.1：证据如何更新前验概率分布

后验是先验和可能性的乘积，除以证据。因此，它反映了假设的概率分布，通过考虑先前的假设和数据更新。从不同的角度来看，后验概率是应用链式规则得出的，链式规则反过来又分解了数据和参数的联合分布。

随着高维连续变量的增加，公式变得更加复杂，并且涉及（多重）积分。此外，另一种公式使用优势度将后验优势度表示为前验优势度乘以似然比的乘积（见 Gelman et al.2013）。

## 精确推断-最大后验概率估计

贝叶斯规则用于精确计算后验概率的实际应用非常有限。这是因为分母中证据项的计算相当具有挑战性。证据反映了观测数据在所有可能参数值上的概率。它也被称为*边际似然*，因为它需要通过对参数的分布进行相加或积分来“边缘化”参数的分布。这通常仅在具有少量离散参数且假设值很少的简单情况下可行。

**最大后验概率**（**MAP**）估计利用证据是一个常数因子这一事实来衡量后验概率，以满足概率分布的要求。由于证据不依赖于![](../Images/B15439_10_006.png)，后验分布与似然和先验的乘积成正比。因此，MAP 估计选择在给定观测数据和先验信念的情况下使后验概率最大化的![](../Images/B15439_10_006.png)值，即后验概率的模式。

MAP 方法将定义**概率分布**的参数的与**最大似然估计**（**最大似然估计**）进行对比。最大似然估计选取使观察到的训练数据的似然函数最大化的参数值![](../Images/B15439_10_006.png)。

通过查看定义，可以发现**MAP 与 MLE 的不同之处在于包含了先验分布**。换句话说，除非先验值为常数，否则 MAP 估计值将与其 MLE 对应值不同：

<figure class="mediaobject">![](../Images/B15439_10_007.png)</figure>

MLE 解决方案倾向于反映频率主义的概念，即概率估计应反映观察到的比率。另一方面，先验对 MAP 估计的影响通常对应于向 MLE 添加反映先验假设的数据。例如，通过添加倾斜的试验数据，可以将硬币有偏差的强先验信息纳入 MLE 上下文中。

先验分布是贝叶斯模型的重要组成部分。现在我们将介绍一些方便的选择，以便于分析推断。

### 如何选择优先级

先验应反映有关参数分布的知识，因为它影响 MAP 估计。如果事先不确定，我们需要做出选择，通常是从几个合理的选项中做出选择。一般来说，通过测试备选方案是否会得出相同的结论来证明先验知识并检查稳健性是一种良好的做法。

有几种类型的先验知识：

*   **目的**先验知识使数据对后验知识的影响最大化。如果参数分布未知，我们可以在相关参数值范围内选择一个类似均匀分布的无信息先验，也称为*平坦先验*。
*   相比之下，**主观**先验旨在将模型外部的信息纳入估算。在布莱克·利特曼（Black Litterman）的背景下，投资者对资产未来回报的信念就是一个主观先验的例子。
*   **经验**先验结合了贝叶斯方法和频率分析方法，并使用历史数据消除主观性，例如，通过估计各种时刻来拟合标准分布。使用一些每日收益的历史平均值，而不是对未来收益的信念，将是一个简单的经验先验的例子。

在 ML 模型的上下文中，先验可以被视为正则化器，因为它限制了后验可以假设的值。例如，先验概率为零的参数不是后验分布的一部分。一般来说，更好的数据可以得出更有力的结论，并减少先前数据的影响。

### 如何保持推理简单-共轭先验

当产生的后验分布与先验分布属于同一类或同一系列分布时，先验分布与似然度是共轭的，不同的参数除外。例如，当先验和似然都是正态分布时，那么后验也是正态分布的。

先验和似然的共轭性意味着后验的**闭式解，这有助于更新过程，避免了使用数值方法来近似后验。此外，得到的后验值可以用作下一更新步骤的前验值。**

让我们用一个股票价格变动的二进制分类示例来说明这个过程。

### 资产价格变动的动态概率估计

当数据由二元贝努利随机变量组成，且具有一定的成功概率，可获得肯定的结果时，重复试验的成功次数服从二项分布。共轭先验是贝塔分布，在区间[0，1]上有支撑，并有两个形状参数来模拟成功概率上的任意先验分布。因此，后验分布也是贝塔分布，我们可以通过直接更新参数得出。

我们将收集不同大小的**二值化每日 S&P500 收益**样本，积极结果是价格上涨。从为区间[0，1]中的每个可能成功概率分配相等概率的非信息先验开始，我们计算不同证据样本的后验概率。

以下代码示例显示，更新只需将观察到的成功和失败次数添加到先验分布的参数中，即可获得后验分布：

```
n_days = [0, 1, 3, 5, 10, 25, 50, 100, 500]
outcomes = sp500_binary.sample(n_days[-1])
p = np.linspace(0, 1, 100)
# uniform (uninformative) prior
a = b = 1
for i, days in enumerate(n_days):
    up = outcomes.iloc[:days].sum()
    down = days - up
    update = stats.beta.pdf(p, a + up , b + down) 
```

所得的后验分布如下图所示。它们说明了从将所有成功概率视为同等可能的统一先验到逐渐达到峰值分布的演变过程。

在 500 个样本之后，概率集中在 2010 年至 2017 年 54.7%的实际正向移动概率附近。它还显示了 MLE 和 MAP 估计之间的微小差异，其中后者倾向于略微向均匀先验的预期值靠拢：

<figure class="mediaobject">![](../Images/B15439_10_02.png)</figure>

图 10.2：标准普尔 500 指数在 500 次更新后第二天上涨的概率后验分布

在实践中，共轭先验的使用仅限于低维情况。此外，简化 MAP 方法避免了计算证据项，但有一个关键缺点，即使它可用：它不返回分布，因此我们可以导出不确定性度量或将其用作先验。因此，我们需要借助数值方法和随机模拟的近似推理，而不是精确推理，我们将在下面介绍。

## 确定性与随机近似推理

对于大多数与实际相关的模型，不可能通过分析推导出精确的后验分布并计算潜在参数的期望值。模型可能有太多的参数，或者后验分布对于分析解来说太复杂：

*   对于**连续变量**，积分可能没有闭式解，而空间的维数和被积函数的复杂性可能会阻止数值积分。
*   对于**离散变量**，边缘化涉及对隐藏变量的所有可能配置求和，虽然这在原则上总是可能的，但我们经常发现，在实践中，可能存在指数级的许多隐藏状态，这使得计算成本高得让人望而却步。

尽管对于一些应用，未观测参数的后验分布将是有趣的，但通常主要需要评估预期，例如，进行预测。在这种情况下，我们可以依赖近似推理，其中包括随机和确定性方法：

*   基于**马尔可夫链蒙特卡罗**（**MCMC**）抽样的**随机**技术已经在许多领域推广了贝叶斯方法的使用。它们通常具有收敛到精确结果的性质。在实践中，采样方法可能需要计算，并且通常仅限于小规模问题。
*   **确定性**方法称为**变分推理**或**变分贝叶斯**是基于对后验分布的解析近似，可以很好地扩展到大型应用。他们做出简化的假设，例如，后验因子以特定方式分解，或者它具有特定的参数形式，如高斯分布。因此，它们不能产生准确的结果，可以作为抽样方法的补充。

我们将在以下两个部分中概述这两种方法。

### 马尔可夫链蒙特卡罗抽样

抽样约为从给定分布*p*（*X*）中抽取样本*X*=（*X*1、*X*<sub xmlns:epub="http://www.idpf.org/2007/ops" class="Subscript--PACKT-">n</sub>）。假设样本是独立的，大数定律确保对于数量不断增加的样本，样本中给定实例*x*<sub xmlns:epub="http://www.idpf.org/2007/ops" class="Subscript--PACKT-">i</sub>的分数（对于离散情况）对应于其概率*p*（*x*=*x*<sub xmlns:epub="http://www.idpf.org/2007/ops" class="Subscript--PACKT-">i</sub>。在连续情况下，类比推理适用于样本空间的给定区域。因此，样本上的平均值可用作分布参数期望值的无偏估计。

一个实际挑战是确保独立采样，因为分布未知。依赖样本可能仍然是无偏的，但往往会增加估计的方差，因此需要更多的样本才能获得与独立样本同样精确的估计。

当状态数随维数呈指数增长时，从多元分布进行采样需要计算。许多算法促进了这一过程；这里我们将介绍一些基于 MCMC 的方法的流行变体。

**马尔可夫链**是一个动态随机模型，描述了通过转移概率连接的一组状态上的随机游动。马尔可夫特性规定进程没有内存，下一步只取决于当前状态。换句话说，这取决于现在、过去和未来是否是独立的，也就是说，关于过去状态的信息无助于预测我们从现在知道的未来之外的未来。

**蒙特卡罗方法**依赖重复随机抽样来近似可能是确定性的结果，但不允许精确的分析解。它是在曼哈顿计划（Manhattan Project）期间开发的，用于在原子水平上估算能量，并获得了其持久的代号，以确保保密性。

许多算法将蒙特卡罗方法应用于马尔可夫链，通常如下所示：

1.  从当前位置开始
2.  从提案分发中提取新职位
3.  根据数据和先验分布评估新位置的概率
    1.  如果可能性足够大，则移动到新位置
    2.  否则，请保持在当前位置
4.  从*开始重复第 1 步*
5.  在给定的迭代次数后，返回所有接受的位置

MCMC 方法的目的是识别和探索后壁的有趣区域，这些区域集中了显著的概率密度。当无记忆过程在接受率增加的后验概率状态附近不断移动时，称其为收敛。一个关键的挑战是平衡随机探索样本空间的需要和降低接受率的风险。

该过程的初始步骤可能比后面步骤更能反映起始位置，并且通常作为*老化***样品**丢弃。MCMC 的一个关键属性是，经过一定次数（但未知）的迭代后，进程应该“忘记”其初始位置。

剩下的样本被称为过程的**轨迹**。假设收敛，样本的相对频率近似于后验值，可以根据大数定律计算期望值。

如前所述，估计的精度取决于随机游走采集的样本的序列相关性，通过设计，每个样本仅取决于之前的状态。较高的相关性限制了对后路的有效探查，需要进行诊断测试。

设计这种马尔可夫链的一般技术包括吉布斯抽样、大都会黑斯廷斯算法和最近的哈密顿 MCMC 方法，这些方法往往表现得更好。

#### 吉布斯抽样

吉布斯抽样将多元抽样简化为一系列一维绘图。从某个起点开始，在对*n*<sup class="Superscript--PACKT-">th</sup>变量进行采样时，迭代保持*n*-1 变量不变。它包含此示例并重复它。

该算法非常简单，易于实现，但会产生高度相关的样本，从而减慢收敛速度。顺序性也阻止了并行化。有关详细说明和解释，请参见 Casella 和 George（1992）。

#### 大都会黑斯廷斯抽样

Metropolis Hastings 算法根据其当前状态随机提出新位置。这样做是为了有效地探索样本空间，减少样本相对于吉布斯抽样的相关性。为了确保它从后验数据中取样，它使用与后验数据成比例的先验和可能性的乘积来评估提案。它接受的概率取决于相对于当前样本对应值的结果。

提案评估方法的一个关键好处是，它可以按比例而不是精确地评估后验结果。但是，可能需要很长时间才能收敛。这是因为与后部无关的随机运动会降低接受率，因此大量步骤只产生少量（潜在相关）样本。可以通过减少提案分布的方差来调整接受率，但由此产生的较小步骤意味着较少的探索。参见 Chib 和 Greenberg（1995）对算法的详细介绍。

#### 哈密顿蒙特卡罗-疯狂

**哈密顿蒙特卡罗**（**HMC**是一种混合方法，利用似然梯度的一阶导数信息。由此，它提出了新的探索状态，并克服了 MCMC 的一些挑战。此外，它还结合了动量来有效地“跳跃”后部。因此，它比简单的随机游走 Metropolis 或 Gibbs 采样更快地收敛到高维目标分布。有关全面的概念介绍，请参见 Betancourt（2018）。

**无 U 形转弯取样器**（**螺母**、Hoffman 和 Gelman 2011）是一个自调整 HMC 扩展，在选择方案之前自适应调节后部移动的大小和数量。它可以很好地处理高维和复杂的后验分布，并允许在没有关于拟合算法本身的专门知识的情况下拟合许多复杂模型。正如我们将在下一节中看到的，它是**PyMC3**中的默认采样器。

### 变分推理与自动微分

**变分推理**（**VI**是一种通过优化逼近概率密度的 ML 方法。在贝叶斯环境中，它近似于后验分布，如下所示：

1.  选择一个参数化的概率分布族
2.  通过 Kullback-Leibler 散度测量，找到最接近目标的该家族成员

与 MCMC 相比，变分 Bayes 收敛速度更快，对大数据的伸缩性更好。MCMC 使用链中的样本逼近后验值，该链最终将任意收敛到目标附近，而变分算法则使用优化结果逼近后验值，但优化结果不能保证与目标一致。

变分推理更适合于大型数据集，例如，数亿个文本文档，因此我们可以快速探索许多模型。相比之下，MCMC 将在较小的数据集上或在时间和计算资源限制较少的情况下提供更准确的结果。例如，如果您花了 20 年时间收集一个小而昂贵的数据集，并且确信您的模型是合适的，并且需要精确的推断，那么 MCMC 将是一个不错的选择。有关更详细的比较，请参见 Salimans、Kingma 和 Welling（2015）。

变分推理的缺点是需要特定于模型的推导和定制优化例程的实现，这会减缓广泛采用。

最近的**自动微分变分推理**（**ADVI**算法将此过程自动化，用户只需指定模型，表示为一个程序，ADVI 自动生成相应的变分算法（实现细节参见 GitHub 上的参考资料）。

我们将看到**PyMC3 支持各种变分推理技术**，包括 ADVI。

# 基于 PyMC3 的概率规划

概率规划提供了一种描述和拟合概率分布的语言，以便我们能够设计、编码、自动估计和评估复杂模型。它的目的是抽象出一些计算和分析的复杂性，使我们能够专注于贝叶斯推理和推理在概念上更直接和直观的方面。

自从 Uber 开源 Pyro（基于 PyTorch）之后出现了新的语言以来，这个领域变得相当活跃。最近，谷歌在 TensorFlow 中增加了一个概率模块。

因此，在 ML 中贝叶斯方法的实际相关性和使用可能会增加，从而产生对不确定性的洞察，特别是对于需要透明而非黑盒模型的用例。

在本节中，我们将介绍流行的**PyMC3**库，它使用 Python 为 ML 模型实现高级 MCMC 采样和变分推理。PyMC3 与**Stan**（以 Stanislaw Ulam 命名，他发明了蒙特卡罗方法，并于 2012 年由哥伦比亚大学的 Andrew Gelman 开发），是最流行的概率编程语言。

## 基于 Theano 的贝叶斯机器学习

PyMC3于 2017 年 1 月发布，将哈密顿 MC方法添加到 PyMC2（2012 年发布）中使用的 Metropolis Hastings 采样器中。PyMC3 使用 Theano 作为其计算后端，用于动态 C 编译和自动区分。Theano 是由 Yoshua Bengio 的**蒙特利尔学习算法研究所**（**MILA**）开发的一个以矩阵为中心且支持 GPU 的优化库，激发了 TensorFlow 的灵感。由于新的深度学习库的成功，MILA 最近停止了对 Theano 的进一步开发（详见*第 16 章*、*收入电话和 SEC 文件的单词嵌入*。

2019 年 12 月在 alpha 中发布的 PyMC4 使用 TensorFlow 而不是 Theano，旨在限制对 API 的影响（参见 GitHub 上存储库的链接）。

## PyMC3 工作流程——预测衰退

PyMC3 旨在提供直观、易读但功能强大的语法，反映统计学家如何描述模型。建模过程通常遵循以下三个步骤：

1.  通过定义以下内容对概率模型进行编码：
    1.  对潜在变量的知识和不确定性进行量化的先验分布
    2.  根据观测数据调节参数的似然函数
2.  使用上一节中描述的选项之一分析后视镜：
    1.  使用映射推断获得点估计
    2.  使用 MCMC 方法从后部采集样本
    3.  用变分贝叶斯逼近后验概率
3.  使用各种诊断工具检查您的型号
4.  生成预测

由此产生的模型可用于推理，以获得对参数值的详细了解，以及预测新数据点的结果。

我们将用一个简单的逻辑回归模型来说明这一工作流程，以预测经济衰退（见笔记本`pymc3_workflow`。随后，我们将使用 PyMC3 计算和比较贝叶斯夏普比率，估计动态对交易比率，并实现贝叶斯线性时间序列模型。

### 数据——领先的衰退指标

我们将使用一个小且简单的数据集，以便我们可以专注于工作流。我们将使用**美联储经济数据**（**弗雷德**）服务（见*第 2 章*、*市场和基础数据——来源和技术*）下载**国家经济研究局**（**定义的美国衰退日期 NBER**）。我们还将获取四个变量，这些变量通常用于预测衰退的开始（Kelley 2019），并可通过 FRED 获得，即：

*   **国债收益率曲线的长期利差**，定义为 10 年期和 3 个月期国债收益率之间的差异
*   密歇根大学的消费者情绪指数 T2 指标
*   **国家金融状况指数**（**NFCI**）
*   NFCI**非金融杠杆**子指数

衰退日期按季度确定；我们将对所有序列的频率进行重新采样，以获得 1982-2019 年的 457 次观测结果。如果四分之一被标记为衰退，那么我们认为这个季度的所有月份都是如此。

我们将建立一个模型，试图回答以下问题：**未来 x 个月内美国经济是否会陷入衰退？**换句话说，我们并不只关注预测衰退的第一个月；这将不平衡限制在 48 个衰退月。

为此，我们需要选择一个交付周期；对于各种领先指标的合适时间范围进行了大量研究：收益率曲线往往在衰退前 24 个月发出信号；NFCI 指标的交付周期往往较短（见 Kelley，2019）。

下表在很大程度上证实了这一经验：它显示了二元衰退变量与 1-24 个月期的四个领先指标之间的相互信息（见*第 6 章*、*机器学习过程*：

<figure class="mediaobject">![](../Images/B15439_10_03.png)</figure>

图 10.3：1-24 个月期间衰退和领先指标之间的相互信息

为了在 NFCI 指标的较短期限和收益率曲线之间取得平衡，我们将选择 12 个月作为预测期限。以下是各指标的分布图，按衰退状态细分：

<figure class="mediaobject">![](../Images/B15439_10_04.png)</figure>

图 10.4：按衰退状态划分的领先指标分布

这表明，当短期利率高于长期利率时，衰退往往与国债收益率曲线的负长期利差相关，也称为反向收益率曲线。NFCI 指标的表现符合我们的预期；情绪指标的关联性似乎最弱。

### 模型定义–贝叶斯逻辑回归

如*第 6 章**机器学习过程*中所述，逻辑回归估计一组特征和二元结果之间的线性关系，该关系由一个 S 形函数介导，以确保模型产生概率。频率分析法得出了参数的点估计，这些参数测量了每个特征对数据点属于正类概率的影响，置信区间基于参数分布的假设。

相反，贝叶斯逻辑回归估计参数本身的后验分布。后验法允许对每个参数的**贝叶斯可信区间**进行更稳健的估计，其好处是模型的不确定性更加透明。

概率程序由**观察到的和未观察到的随机变量**（**RVs**组成。如前所述，我们通过似然分布定义观测到的 RVs，通过先验分布定义未观测到的 RVs。PyMC3 包括许多用于此目的的概率分布。

PyMC3 库使得为逻辑回归执行近似贝叶斯推断变得非常简单。逻辑回归根据*k*特征，对*i*月后 12 个月的经济衰退概率进行建模，如下图左侧所示：

<figure class="mediaobject">![](../Images/B15439_10_05.png)</figure>

图 10.5：贝叶斯逻辑回归

我们将使用上下文管理器`with`来定义一个`manual_logistic_model`，稍后我们可以将其称为概率模型：

1.  截距和两个特征的未观测参数的 RVs 使用非信息先验表示，这些假设正态分布的平均值为 0，标准偏差为 100。
2.  可能性根据逻辑回归的规范将参数与数据相结合。
3.  结果建模为伯努利 RV，成功概率由可能性给出：

    ```
    with pm.Model() as manual_logistic_model:
        # coefficients as rvs with uninformative priors
        intercept = pm.Normal('intercept', 0, sd=100)
        beta_1 = pm.Normal('beta_1', 0, sd=100)
        beta_2 = pm.Normal('beta_2', 0, sd=100)
        # Likelihood transforms rvs into probabilities p(y=1)
        # according to logistic regression model.
        likelihood = pm.invlogit(intercept +
                                 beta_1 * data.yield_curve +
                                 beta_2 * data.leverage)
        # Outcome as Bernoulli rv with success probability
        # given by sigmoid function conditioned on actual data
        pm.Bernoulli(name='logit',
                     p=likelihood,
                     observed=data.recession) 
    ```

#### 模型可视化和板表示法

命令`pm.model_to_graphviz(manual_logistic_model)`产生显示在*图 10.5*右侧的铭牌符号。它将未观测到的参数显示为浅椭圆，将观测到的元素显示为暗椭圆。矩形表示模型定义中包含的数据所隐含的观察模型元素的重复次数。

#### 广义线性模型模

PyMC3 包括许多通用模型，因此我们可以限制自定义应用程序的手动规范。

以下代码定义了与**广义线性模型**（**GLM**家族成员相同的逻辑回归。它使用受统计语言 R 启发的公式格式来实现，并通过 patsy 库移植到 Python：

```
with pm.Model() as logistic_model:
    pm.glm.GLM.from_formula(recession ~ yield_curve + leverage,
                            data,
                            family=pm.glm.families.Binomial()) 
```

### 精确地图推理

我们使用刚刚定义的模型的`.find_MAP()`方法获得三个参数的点图估计。正如预期的那样，较低的利差值会增加衰退概率，较高的杠杆率也会增加（但程度较小）：

```
with logistic_model:
    map_estimate = pm.find_MAP()
print_map(map_estimate)
Intercept     -4.892884
yield_curve   -3.032943
leverage       1.534055 
```

PyMC3 使用拟牛顿**Broyden Fletcher Goldfarb Shanno**（**BFGS**算法）解决了寻找密度最高的后验点的优化问题，但提供了 SciPy 库提供的几种备选方案。

地图点估计值与相应的`statsmodels`系数相同（参见笔记本`pymc3_workflow`。

### 近似推理-MCMC

如果我们只对模型参数的点估计感兴趣，那么对于这个简单的模型，MAP 估计就足够了。更复杂的自定义概率模型需要抽样技术来获得参数的后验概率。

我们将使用模型及其所有变量来说明 MCMC 推断：

```
formula = 'recession ~ yield_curve + leverage + financial_conditions + sentiment'
with pm.Model() as logistic_model:
    pm.glm.GLM.from_formula(formula=formula,
                            data=data,
                            family=pm.glm.families.Binomial())
# note that pymc3 uses y for the outcome
logistic_model.basic_RVs
[Intercept, yield_curve, leverage, financial_conditions, sentiment, y] 
```

请注意，在非常不同的尺度上测量的变量可能会减慢采样过程。因此，我们首先应用 scikit learn 提供的`scale()`功能来标准化所有特性。

一旦我们用新的公式定义了这样的模型，我们就可以进行推理来近似后验分布。MCMC 采样算法可通过`pm.sample()`功能获得。

默认情况下，PyMC3 会自动选择效率最高的采样器，并初始化采样过程以实现高效收敛。对于连续模型，PyMC3 选择上一节讨论的 NUTS 取样器。它还通过 ADVI 运行变分推理，为采样器找到良好的启动参数。几种备选方案之一是使用 MAP 估算。

为了观察收敛的效果，我们首先在对采样器进行 1000 次迭代调优后只绘制 100 个样本。这些将被丢弃。可使用`cores`参数对多条链并行化采样过程（使用 GPU 时除外）：

```
with logistic_model:
    trace = pm.sample(draws=100,
                      tune=1000,
                      init='adapt_diag',
                      chains=4,
                      cores=4,
                      random_seed=42) 
```

结果`trace`包含每个 RV 的采样值。我们可以使用`plot_traces()`功能检查链的后验分布：

```
plot_traces(trace, burnin=0) 
```

*图 10.6*显示了前两个特征及其截距随时间的样本分布及其值（完整输出见笔记本）。此时，采样过程尚未收敛，因为对于每个特征，四条记录道产生的结果截然不同；左五个面板中垂直显示的数字是由四条记录道生成的分布模式的平均值：

<figure class="mediaobject">![](../Images/B15439_10_06.png)</figure>

图 10.6：100 个样品后的痕迹

我们可以通过提供先前运行的跟踪作为输入来继续采样。在额外的 20000 个样本之后，我们观察到一幅完全不同的图片，如下图所示。这显示了采样过程现在如何更接近收敛。此外，请注意，初始系数点估计值相对接近当前值：

<figure class="mediaobject">![](../Images/B15439_10_07.png)</figure>

图 10.7：额外 50000 个样本后的痕迹

我们可以计算**可信区间**，置信区间的贝叶斯对应物，作为轨迹的百分位数。由此产生的边界反映了我们对给定概率阈值的参数值范围的信心，而不是大量试验中参数在该范围内的次数。*图 10.8*显示了变量收益率曲线和杠杆率的可信区间，表示为将*e*提高到系数值的幂次所产生的优势比（参见*第 7 章*、*线性模型——从风险因素到回报预测*。

具体实施见笔记本`pymc3_workflow`：

<figure class="mediaobject">![](../Images/B15439_10_08.png)</figure>

图 10.8：收益率曲线和杠杆率的可信区间

### 近似推理-变分贝叶斯

变分推理的接口与 MCMC 实现非常相似。我们只使用`fit()`而不是`sample()`函数，如果分布拟合过程收敛到给定公差，我们可以选择包括提前停止`CheckParametersConvergence`回调：

```
with logistic_model:
    callback = CheckParametersConvergence(diff='absolute')
    approx = pm.fit(n=100000,
                    callbacks=[callback]) 
```

我们可以从近似分布中提取样本以获得跟踪对象，正如我们之前对 MCMC 采样器所做的那样：

```
trace_advi = approx.sample(10000) 
```

对跟踪摘要的检查表明，结果的准确性稍差。

### 模型诊断

贝叶斯模型诊断包括验证采样过程已收敛且一致地从后验概率高的区域采样，以及确认模型很好地代表了数据。

#### 汇聚

我们可以可视化样本随时间的变化及其分布，以检查结果的质量。下图所示的图表分别显示了初始 100 个样本和额外 200000 个样本后的后验分布，并说明了收敛意味着多条链如何识别相同的分布：

<figure class="mediaobject">![](../Images/B15439_10_09.png)</figure>

图 10.9：400 和超过 200000 个样品后的痕迹

PyMC3 为采样器生成各种摘要统计信息。这些可作为 stats 模块中的单个函数使用，或通过提供对函数`pm.summary()`的跟踪来使用。

下表包括第一列中的（单独计算的）statsmodels logit 系数，以表明在这种简单情况下，两个模型略微一致，因为样本平均数与系数不匹配。这可能是由于高度的准分离：收益率曲线的高可预测性允许对 17%的数据点进行完美预测，这反过来导致逻辑回归的 MLE 估计定义不清（更多信息，请参见笔记本中的 statsmodels 输出）：

<colgroup><col> <col> <col> <col> <col> <col> <col> <col></colgroup> 
| 参数 | statsmodels | PyMC3 |
| 系数 | 意思是 | SD | HPD 3% | HPD 97% | 有效样本 | R 帽 |
| 拦截 | -5.22 | -5.47 | 0.71 | -6.82 | -4.17 | 68,142 | 1 |
| 屈服曲线 | -3.30 | -3.47 | 0.51 | -4.44 | -2.55 | 70,479 | 1 |
| 影响力 | 1.98 | 2.08 | 0.40 | 1.34 | 2.83 | 72,639 | 1 |
| 财务状况 | -0.65 | -0.70 | 0.33 | -1.33 | -0.07 | 91,104 | 1 |
| 观点 | -0.33 | -0.34 | 0.26 | -0.82 | 0.15 | 106,751 | 1 |

其余列包含最小宽度可信区间的**最高后验密度**（**HPD**）估计值，即置信区间的贝叶斯版本，在此，该置信区间在 95%的水平上计算。`n_eff`统计汇总了![](../Images/B15439_10_009.png)抽签产生的有效（未拒收）样本数量。

R-hat，也称为**Gelman-Rubin 统计量**，通过比较链间方差和链内方差来检查收敛性。如果采样器收敛，这些方差应该相同，也就是说，链应该看起来相似。因此，统计数据应该接近 1。

对于具有多个变量的高维模型，检查大量轨迹变得很麻烦。使用 NUTS 时，能量图有助于我们评估收敛问题。它总结了随机过程探索后验概率的效率。该图显示了能量和能量转移矩阵，它们应该很好地匹配，如下图右侧面板中的示例所示：

<figure class="mediaobject">![](../Images/B15439_10_10.png)</figure>

图 10.10：森林和能源图

#### 后验预测检查

**后验预测检查**（**PPCs**）对于检查模型与数据的拟合程度非常有用。他们通过从模型中生成数据，使用后验曲线绘制的参数。为此，我们使用`pm.sample_ppc`功能，为每次观察获取*n*个样本（GLM 模块自动将结果命名为`'y'`：

```
ppc = pm.sample_ppc(trace_NUTS, samples=500, model=logistic_model)
ppc['y'].shape
(500, 445) 
```

我们可以使用接收机工作特性曲线下的面积（AUC，参见*第 6 章*、*机器学习过程*分数来评估样本内拟合，例如，比较不同模型：

```
roc_auc_score(y_score=np.mean(ppc['y'], axis=0),
              y_true=data.income)
0.9483627204030226 
```

结果相当高，接近 0.95。

### 如何生成预测

在运行后验预测检查之前，预测使用 Theano 的*共享变量*将训练数据替换为测试数据。为了便于可视化和简化说明，我们使用收益率曲线变量作为唯一的预测变量，并忽略数据的时间序列性质。

相反，我们使用 scikit learn 的基本`train_test_split()`功能创建训练集和测试集，并根据结果分层，以保持班级不平衡：

```
X = data[['yield_curve']]
labels = X.columns
y = data.recession
X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    test_size=0.2,
                                                    random_state=42,
                                                    stratify=y) 
```

然后，我们为该训练集创建一个共享变量，并在下一步用测试集替换该变量。请注意，我们需要使用 NumPy 数组并提供列标签列表：

```
X_shared = theano.shared(X_train.values)
with pm.Model() as logistic_model_pred:
    pm.glm.GLM(x=X_shared, labels=labels,
               y=y_train, family=pm.glm.families.Binomial()) 
```

然后，我们运行采样器，与之前一样：

```
with logistic_model_pred:
    pred_trace = pm.sample(draws=10000,
                           tune=1000,
                           chains=2,
                           cores=2,
                           init='adapt_diag') 
```

现在，我们用测试数据替换共享变量上的列车数据，并将`pm.sample_ppc`函数应用于生成的`trace`：

```
X_shared.set_value(X_test)
ppc = pm.sample_ppc(pred_trace,
                    model=logistic_model_pred,
                    samples=100)
y_score = np.mean(ppc['y'], axis=0)
roc_auc_score(y_score=np.mean(ppc['y'], axis=0),
              y_true=y_test)
0.8386 
```

这个简单模型的 AUC 得分为 0.86。显然，如果培训集已经包含了近几个月来的衰退实例，那么预测下一个月同样的衰退就容易多了。请记住，我们使用此模型仅用于演示目的。

*图 10.11*绘制了从 100 个蒙特卡罗链中取样的预测及其周围的不确定性，以及与模型预测相对应的实际二元结果和逻辑曲线：

<figure class="mediaobject">![](../Images/B15439_10_11.png)</figure>

图 10.11：单变量模型预测

### 总结和要点

我们建立了一个简单的逻辑回归模型，用四个领先指标预测美国经济在 12 个月内陷入衰退的可能性。对于这个简单的模型，我们可以得到系数值的精确映射估计，然后我们可以使用这些估计来参数化模型并进行预测。

然而，更复杂的自定义概率模型将不允许这种捷径，地图估计也无法洞察点估计之外的后验分布。因此，我们演示了如何使用 PyMC3 运行近似推理。结果说明了我们如何了解每个模型参数的后验分布，但也表明，即使对于小模型，计算成本也比 statsmodels MLE 估计显著增加。尽管如此，对于复杂的概率模型，基于抽样的解决方案是了解数据的唯一途径。

现在我们将继续说明如何将贝叶斯分析应用于一些与交易相关的用例。

# 贝叶斯交易模型

现在，我们已经熟悉了 ML 的贝叶斯方法和 PyMC3 的概率编程，让我们来探讨几个相关的交易相关应用程序，即：

*   将夏普比率建模为概率模型，以便进行更深入的性能比较
*   利用贝叶斯线性回归计算成对交易套期保值比率
*   从贝叶斯角度分析线性时间序列模型

**Thomas Wiecki**是PyMC3 的主要作者之一，也是 Quantopian 数据科学的负责人，他已经创建了几个例子，下面的章节将以这些例子为基础。PyMC3 文档有许多附加教程（请参阅 GitHub 以获取链接）。

## 用于性能比较的贝叶斯夏普比率

在本节中，我们将说明：

*   如何使用 PyMC3 将**夏普比率**（**SR**定义为概率模型
*   如何比较不同收益率序列的后验分布

两个系列的贝叶斯估计提供了非常丰富的见解，因为它提供了效应大小、组 SR 均值及其差异以及标准偏差及其差异的可信值的完整分布。Python 的实现归功于 Thomas Wiecki，其灵感来源于 R 包 BEST（Meredith 和 Kruschke，2018）。

贝叶斯 SR 的相关用例包括分析备选策略之间的差异，或分析策略的样本内返回和样本外返回之间的差异（详情参见笔记本`bayesian_sharpe_ratio`。Bayesian SR 也是 pyfolio 的 Bayesian tearsheet 的一部分。

### 定义自定义概率模型

为了将 SR 建模为概率模型，我们需要关于收益分布的先验知识和控制该分布的参数。对于低**自由度**（**DF**）而言，Student t 分布相对于正态分布显示出肥尾，是捕捉这方面收益的合理选择。

因此，我们需要**对该分布**的三个参数进行建模，即收益率的平均值和标准差，以及 DF。我们将分别假设平均值和标准偏差的正态分布和均匀分布，以及 DF 的指数分布，期望值足够低，以确保厚尾。

回报基于这些概率输入，年化 SR 结果来自标准计算，忽略无风险利率（使用每日回报）。我们将提供 2010-2018 年的 AMZN 股票回报作为输入（有关数据准备的更多信息，请参阅笔记本）：

```
mean_prior = data.stock.mean()
std_prior = data.stock.std()
std_low = std_prior / 1000
std_high = std_prior * 1000
with pm.Model() as sharpe_model:
    mean = pm.Normal('mean', mu=mean_prior, sd=std_prior)
    std = pm.Uniform('std', lower=std_low, upper=std_high)
    nu = pm.Exponential('nu_minus_two', 1 / 29, testval=4) + 2
    returns = pm.StudentT('returns', nu=nu, mu=mean, sd=std,
observed=data.stock)
    sharpe = returns.distribution.mean / returns.distribution.variance ** 
.5 * np.sqrt(252)
    pm.Deterministic('sharpe', sharpe) 
```

我们在 PyMC3 工作流程的前一节中介绍的图版符号可视化了三个参数及其关系，以及我们在下图中提供的返回和观察次数：

<figure class="mediaobject">![](../Images/B15439_10_12.png)</figure>

图 10.12：板内贝叶斯 SR 符号

然后，我们运行上一节介绍的 MCMC 采样过程（参见笔记本`bayesian_sharpe_ratio`了解遵循熟悉工作流的实现细节）。在对四条链中的每一条链进行大约 25000 个样本后，我们获得了模型参数的后验分布，如下图所示：

```
plot_posterior(data=trace); 
```

<figure class="mediaobject">![](../Images/B15439_10_13.png)</figure>

图 10.13：模型参数的后验分布

现在我们知道了如何评估单个资产或投资组合的 SR，让我们看看如何使用贝叶斯 SR 比较两个不同收益序列的性能。

### 两种返回序列的性能比较

为了比较两个收益率序列的表现，我们将分别对各组的 SR 进行建模，并计算效应大小作为波动率调整收益率之间的差异。下图中显示的相应概率模型自然更大，因为它包括两个 SRs 及其差值：

<figure class="mediaobject">![](../Images/B15439_10_14.png)</figure>

图 10.14：两个贝叶斯 SRs 在板符号中的差异

一旦我们定义了模型，我们通过 MCMC 采样过程运行它，以获得其参数的后验分布。我们使用 2010-2018 年 AMZN 股票的 2037 日收益率，并将其与同期的标准普尔 500 指数收益率进行比较。我们可以在任何策略回溯测试中使用回报，而不是 AMZN 回报。

通过可视化轨迹，可以深入了解每个指标的分布，如*图 10.15*中的各种图所示：

<figure class="mediaobject">![](../Images/B15439_10_15.png)</figure>

图 10.15：两个贝叶斯 SRs 之间差异的后验分布

最重要的指标是底部面板中两个 SRs 之间的差异。考虑到完整的后验分布，从 SR 的角度直观地显示或计算一个收益率序列优越的概率是很简单的。

## 配对交易的贝叶斯滚动回归

在上一章中，我们介绍了配对交易作为一种流行的交易策略，它依赖于两个或多个资产的协整。鉴于这些资产，我们需要估计套期保值比率，以决定多头和空头头寸的相对大小。一种基本方法是使用线性回归。您可以在记事本`rolling_regression`中找到此部分的代码，它遵循 Thomas Wiecki 的滚动回归示例（参见 GitHub 上的 PyMC3 教程链接）。

成对交易候选者的一个流行例子是 ETF GLD，它反映了黄金价格和 GFI 等黄金矿业股票。我们使用 yfinance 获取 2004-2020 年期间的收盘价格数据。*图 10.16*的左面板显示了历史价格序列，而右面板显示了历史价格的散点图，其中色调表示时间维度，以强调相关性似乎是如何演变的。**请注意，我们应该使用收益**，正如我们在*第 9 章*、*波动预测和统计套利的时间序列模型*中所做的那样，来计算对冲比率；然而，使用价格系列可以创建更引人注目的可视化效果。建模过程本身不受影响：

<figure class="mediaobject">![](../Images/B15439_10_16.png)</figure>

图 10.16：两对候选交易的价格序列和随时间的相关性

我们想说明滚动贝叶斯线性回归如何跟踪两种资产价格之间的关系随时间的变化。其主要思想是通过允许回归系数的变化，将时间维度纳入线性回归。具体而言，我们将假设截距和斜率随时间随机移动：

<figure class="mediaobject">![](../Images/B15439_10_010.png)</figure>

我们使用 PyMC3 的内置`pm.GaussianRandomWalk`过程指定`model_randomwalk`。它要求我们定义截距α和斜率β的标准偏差：

```
model_randomwalk = pm.Model()
with model_randomwalk:
    sigma_alpha = pm.Exponential('sigma_alpha', 50.)
    alpha = pm.GaussianRandomWalk('alpha', 
                                  sd=sigma_alpha,
                                  shape=len(prices))
    sigma_beta = pm.Exponential('sigma_beta', 50.)
    beta = pm.GaussianRandomWalk('beta', 
                                 sd=sigma_beta,
                                 shape=len(prices)) 
```

鉴于概率模型的规范，我们现在将定义回归并将其连接到输入数据：

```
with model_randomwalk:
    # Define regression
    regression = alpha + beta * prices_normed.GLD
    # Assume prices are normally distributed
    # Get mean from regression.
    sd = pm.HalfNormal('sd', sd=.1)
    likelihood = pm.Normal('y', 
                           mu=regression, 
                           sd=sd, 
                           observed=prices_normed.GFI) 
```

现在，我们可以运行我们的MCMC 采样器来生成模型参数的后验分布：

```
with model_randomwalk:
    trace_rw = pm.sample(tune=2000, 
                         cores=4, 
                         draws=200, 
                         nuts_kwargs=dict(target_accept=.9)) 
```

*图 10.17*描述了截距和斜率系数多年来的变化，强调了不断变化的相关性：

<figure class="mediaobject">![](../Images/B15439_10_17.png)</figure>

图 10.17：截距和斜率系数随时间的变化

使用动态回归系数，我们现在可以想象滚动回归所建议的套期保值比率在使用这种贝叶斯方法（将系数建模为随机游动）的几年中会发生怎样的变化。

下图结合了价格系列和回归线，其中色调再次表示时间线（在笔记本中查看颜色输出）：

<figure class="mediaobject">![](../Images/B15439_10_18.png)</figure>

图 10.18：滚动回归线和价格序列

在最后一个例子中，我们将实现一个贝叶斯随机波动率模型。

## 随机波动率模型

如前一章所述，资产价格具有时变波动性。在某些时期，回报是高度可变的，而在另一些时期，回报是非常稳定的。我们在*第 9 章*、*波动预测和统计套利时间序列模型*中介绍了从经典线性回归角度应对这一挑战的 ARCH/GARCH 模型。

贝叶斯随机波动率模型通过一个潜在的波动率变量（建模为随机过程）捕捉这种波动现象。不掉头取样器是使用这种模型引入的（Hoffman 等人，2011 年），笔记本`stochastic_volatility`用 2000 年后 S&P 500 的每日数据说明了这个用例。*图 10.19*显示了整个期间的几个波动性集群：

<figure class="mediaobject">![](../Images/B15439_10_19.png)</figure>

图 10.19：每日标准普尔 500 指数日志回报

概率模型规定对数收益遵循 t 分布，该分布具有厚尾，这也是资产收益通常观察到的情况。t 分布由参数*ν*控制，该参数表示 DF。它也被称为正态性参数，因为当*ν*增加时，t 分布接近正态分布。假设该参数与参数![](../Images/B15439_10_011.png)呈指数分布。

此外，假设对数收益的平均值为零，而标准偏差遵循随机游动，标准偏差也具有指数分布：

<figure class="mediaobject">![](../Images/B15439_10_012.png)</figure>

我们在 PyMC3 中实现此模型，如下所示，以反映其概率规范，使用日志返回匹配模型：

```
prices = pd.read_hdf('../data/assets.h5', key='sp500/prices').loc['2000':,
                                                                  'Close']
log_returns = np.log(prices).diff().dropna()
with pm.Model() as model:
    step_size = pm.Exponential('sigma', 50.)
    s = GaussianRandomWalk('s', sd=step_size, 
                           shape=len(log_returns))
    nu = pm.Exponential('nu', .1)
    r = pm.StudentT('r', nu=nu, 
                    lam=pm.math.exp(-2*s), 
                    observed=log_returns) 
```

接下来，我们在 2000 个样本的磨合期后绘制 5000 个螺母样本，使用比默认值 0.8 更高的接受率，正如 PyMC3 文档为有问题的后期推荐的那样（参见 GitHub 上的相应链接）：

```
with model:
    trace = pm.sample(tune=2000, 
                      draws=5000,
                      nuts_kwargs=dict(target_accept=.9))
Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [nu, s, sigma]
Sampling 4 chains, 0 divergences: 100%|██████████| 28000/28000 [27:46<00:00, 16.80draws/s]
The estimated number of effective samples is smaller than 200 for some parameters. 
```

四条链总共 28000 个样本后，下图中的轨迹图确认采样过程已收敛：

<figure class="mediaobject">![](../Images/B15439_10_20.png)</figure>

图 10.20：随机波动率模型的轨迹图

当我们在*图 10.21*中绘制样本与 S&P500 回报的对比图时，我们发现这个简单的随机波动率模型很好地跟踪了波动率集群：

<figure class="mediaobject">![](../Images/B15439_10_21.png)</figure>

图 10.21：模型

请记住，这表示样本中的拟合。作为下一步，您应该尝试评估预测准确性。我们在前面的滚动线性回归小节中介绍了如何进行预测，并在前面的几章中使用了时间序列交叉验证，这为您提供了实现此目的所需的所有工具！

# 总结

在本章中，我们探讨了机器学习的贝叶斯方法。我们发现，它们有几个优点，包括编码先验知识或观点的能力，对模型估计和预测周围的不确定性有更深入的了解，以及适用于在线学习，其中每个训练样本都会逐渐影响模型的预测。

我们学习了使用 PyMC3 将贝叶斯工作流从模型规范应用到评估、诊断和预测，并探索了几个相关应用。我们将在*第 14 章*、*交易文本数据–情绪分析*中遇到更多的贝叶斯模型，其中我们将讨论自然语言处理和主题建模；在*第 20 章*、*条件风险因素和资产定价自动编码器*中会遇到更多的贝叶斯模型，在这里我们将介绍变分自动编码器。

下一章将介绍基于树的非线性模型，即决策树，并展示如何将多个模型组合成一个树集合来创建随机森林。