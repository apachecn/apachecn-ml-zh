# 19

# 用于多元时间序列和情绪分析的 RNN

上一章介绍了如何设计**卷积神经网络**（**CNN**）来学习表示栅格数据空间结构的特征，尤其是图像，以及时间序列。本章介绍了**递归神经网络**（**RNN**），该网络专门研究序列数据，其中模式随时间演化，学习通常需要记忆前面的数据点。

**前馈神经网络**（**FFNNs**）将每个样本的特征向量视为独立的、同分布的。因此，在评估当前观测时，他们不考虑先前的数据点。换句话说，他们没有记忆。

CNN 使用的一维和二维卷积滤波器可以提取特征，这些特征通常是少量相邻数据点的函数。但是，它们只允许浅层参数共享：每个输出都是将相同的过滤器应用于相关时间步长和特征的结果。

RNN 模型的主要创新在于，每个输出都是先前输出和新信息的函数。因此，RNN 可以在使用当前特征向量执行的计算中包含有关先前观测的信息。这种循环公式能够在更深层的计算图上实现参数共享（Goodfello、Bengio 和 Courville，2016）。在本章中，您将遇到**长短期记忆**（**LSTM**单元）和**门控循环单元**（**GRUs**单元），它们旨在克服与学习长程依赖相关的消失梯度的挑战，需要通过多个连接传播错误的位置。

成功的 RNN 用例包括需要将一个或多个输入序列映射到一个或多个输出序列并突出自然语言应用程序的各种任务。我们将探讨如何将 RNN 应用于单变量和多变量时间序列，以使用市场或基础数据预测资产价格。我们还将介绍 RNN 如何利用词语嵌入的替代文本数据，我们在*第 16 章*、*收益通知和 SEC 文件*中介绍了词语嵌入，以对文档中表达的情绪进行分类。最后，我们将使用 SEC 文件中信息量最大的部分来学习单词嵌入，并预测文件日期前后的回报。

更具体地说，在本章中，您将了解以下内容：

*   循环连接如何允许 RNN 记忆模式并模拟隐藏状态
*   RNNs 计算图的展开与分析
*   门控单元如何学习从数据调节 RNN 内存以实现远程依赖
*   Python 中单变量和多变量时间序列 RNN 的设计与训练
*   如何使用 RNN 学习单词嵌入或使用预先训练的单词向量进行情感分析
*   使用自定义单词嵌入构建双向 RNN 预测股票收益

您可以在本章的 GitHub 存储库目录中找到代码示例和其他资源。

# 递归神经网络的工作原理

RNN 假设输入数据已按顺序生成，因此先前的数据点会影响当前观测值，并与预测后续值相关。因此，它们允许比 FFNN 和 CNN 更复杂的输入输出关系，FFNN 和 CNN 被设计为使用给定数量的计算步骤将一个输入向量映射到一个输出向量。相反，RNN 可以为输入、输出或两者最好地表示为向量序列的任务建模数据。有关详细概述，请参阅古德费罗、本吉奥和库尔维尔（2016）中的*第 10 章*。

*图 19.1*中的图表受 Andrew Karpath 2015 年的博客文章*递归神经网络*的不合理有效性的启发（参见 GitHub 的链接），说明了使用一个或多个神经网络层执行的非线性变换从输入向量到输出向量的映射：

![](img/B15439_19_01.png)

图 19.1：各种类型的序列到序列模型

左面板显示了固定大小向量之间的一对一映射，这是前两章介绍的 FFN 和 CNN 的典型情况。其他三个面板显示了各种 RNN 应用程序，通过对新输入和上一次迭代产生的状态应用循环变换，将输入向量映射到输出向量。到 RNN 的*x*输入向量也称为**上下文**。

向量是时间索引的，这通常是交易相关应用程序所需要的，但它们也可以用一组不同的顺序值来标记。通用序列到序列映射任务和示例应用程序包括：

*   **一对多**：图像字幕，例如采用单个像素向量（如前一章所述），并将其映射到一个单词序列。
*   **多对一**：情绪分析获取一系列单词或标记（参见*第 14 章*、*交易文本数据–情绪分析*并将其映射到输出标量或向量。
*   **多对多**：以同步（如图所示）或异步方式将输入向量的视频帧映射序列机器翻译或标记为输出向量的序列。多变量时间序列的多步预测也将多个输入向量映射到多个输出向量。

请注意，输入和输出序列可以是任意长度的，因为可以根据需要多次应用固定但从数据中学习的循环变换。

正如 CNN 很容易扩展到大型图像，一些 CNN 可以处理可变大小的图像一样，RNN 可以扩展到比不适合基于序列的任务的网络更长的序列。大多数 RNN 还可以处理可变长度的序列。

## 用圈展开计算图

RNN 被称为递归，因为它们将相同的转换应用于序列的每个元素，RNN 的输出取决于先前迭代的结果。因此，RNN 保持一个**内部状态**，它捕获序列中先前元素的信息，就像内存一样。

*图 19.2*显示了单个隐藏 RNN 单元在训练期间学习两个权重矩阵所隐含的**计算图**：

*   *W*<sub style="font-style: italic;">hh</sub>：应用于前一隐藏状态*h*<sub style="font-style: italic;">t-1</sub>
*   *W*<sub style="font-style: italic;">hx</sub>：应用于电流输入*x*<sub style="font-style: italic;">t</sub>

RNN 的输出*y*<sub style="font-style: italic;">t</sub>是两个矩阵乘法之和的非线性变换，例如使用 tanh 或 ReLU 激活函数：

![](img/B15439_19_001.png)

![](img/B15439_19_02.png)

图 19.2：带有单个隐藏单元的 RNN 计算图的循环和展开视图

等式右侧显示了展开图右侧面板中所示的循环关系的效果。它突出显示了重复的线性代数变换以及将过去序列元素的信息与当前输入或上下文相结合的结果隐藏状态。备选公式仅将上下文向量连接到第一隐藏状态；我们将在下一节中概述修改此基线体系结构的其他选项。

## 时间反向传播

上图中展开的计算图强调了学习过程必须包含给定输入序列的所有时间步。在训练期间更新权重的反向传播算法包括从左到右向前传递以及展开的计算图，然后在相反方向向后传递。

如*第 17 章*、*交易深度学习*中所述，反向传播算法评估损失函数并计算其相对于参数的梯度，以相应地更新权重。在 RNN 上下文中，反向传播在计算图中从右向左运行，从最后一个时间步一直更新到初始时间步的参数。因此，算法被称为**时间反向传播**（Werbos 1990）。

它强调了 RNN 通过在任意数量的序列元素之间共享参数，同时保持相应的状态，从而对长期依赖性建模的能力。另一方面，它在计算上相当昂贵，并且由于其固有的顺序性，每个时间步的计算不能并行化。

## 替代 RNN 体系结构

正如我们在前两章中介绍的 FFNN 和 CNN 体系结构一样，RNN 可以通过多种方式进行优化，以捕获输入和输出数据之间的动态关系。

除了修改隐藏状态之间的循环连接，替代方法还包括循环输出关系、双向 RNN 和编解码器架构。请参阅 GitHub 以获取背景参考，以补充此简要摘要。

### 输出递归与教师强迫

降低隐状态重现计算复杂性的一种方法是将单元的隐状态连接到先前单元的输出，而不是其隐状态。由此产生的 RNN 的容量低于前面讨论的体系结构，但不同的时间步现在是解耦的，可以并行训练。

然而，为了成功地学习相关的过去信息，训练输出样本需要反映该信息，以便反向传播可以相应地调整网络参数。如果资产回报与其滞后价值无关，则财务数据可能不符合这一要求。在输入向量旁边使用先前的结果值称为**教师强迫**（Williams 和 Zipser，1989）。

从输出到后续隐藏状态的连接也可以与隐藏循环结合使用。但是，培训需要时间反向传播，不能并行运行。

### 双向 RNN

对于某些任务，输出不仅依赖于过去的序列元素，而且还依赖于未来的元素，这可能是现实和有益的（Schuster 和 Paliwal，1997）。机器翻译或语音和手写识别是这样的例子：后续序列元素既能提供信息，又能实际用于消除竞争输出的歧义。

对于一维序列，**双向 RNN**将一个向前移动的 RNN 与另一个反向扫描序列的 RNN 组合在一起。因此，输出取决于序列的未来和过去。自然语言和音乐领域的应用（Sigtia et al.，2014）非常成功（参见*第 16 章*、*收入电话和 SEC 备案的单词嵌入*，以及本章中使用 SEC 备案的最后一个示例）。

双向 RNN 也可用于二维图像数据。在这种情况下，一对 RNN 对每个维度中的序列执行正向和反向处理。

### 编码器-解码器架构、注意事项和转换器

到目前为止讨论的架构假设输入和输出序列具有相等的长度。编码器-解码器体系结构，也称为**序列到序列**（**seq2seq**体系结构）放松了这一假设，并在机器翻译和具有此特征的其他应用中非常流行（Prabhavalkar et al.，2017）。

**编码器**是将输入空间映射到不同空间的 RNN，也称为**潜在空间**，而解码器功能是将编码输入映射到目标空间的补充 RNN（Cho 等人，2014）。在下一章中，我们将介绍使用各种深度学习架构在无监督环境中学习特征表示的自动编码器。

编码器和解码器 RNN 联合训练，以便最终编码器隐藏状态的输入成为解码器的输入，解码器反过来学习匹配训练样本。

**注意机制**解决了当输入序列本身大小不同时使用固定大小编码器输入的限制。该机制将原始文本数据转换为分布式表示（参见*第 16 章*、*盈利电话和 SEC 备案的单词嵌入*），存储结果，并使用这些特征向量的加权平均值作为上下文。权重由模型学习，并在增加权重或关注输入的不同元素之间交替。

最近的一种**transformer**架构省去了递归和卷积，完全依赖于这种注意机制来学习输入输出映射。它在机器翻译任务上实现了卓越的质量，同时需要更少的培训时间，尤其是因为它可以并行化（Vaswani et al.，2017）。

## 如何设计深层 RNN

*图 19.2*中的**展开计算图**显示，每个变换都涉及一个线性矩阵运算，然后是一个非线性变换，可以由单个网络层联合表示。

在前面的两章中，我们了解了添加深度如何允许 FFNN，特别是 CNN，学习更有用的层次表示。RNN 还受益于将输入输出映射分解为多个层。对于 RNN，此映射通常会转换：

*   将输入和先前的隐藏状态转换为当前隐藏状态
*   将隐藏状态转换为输出

一种常见的方法是**将循环层**堆叠在彼此的顶部，以便它们学习输入数据的分层时间表示。这意味着较低层可以捕获较高频率的模式，由较高层合成为较低频率的特征，这些特征被证明对分类或回归任务有用。我们将在下一节中演示此方法。

不太流行的替代方案包括在从输入到隐藏状态、隐藏状态之间或从隐藏状态到输出的连接中添加层。这些设计采用跳转连接，以避免时间步长之间的最短路径增加和训练变得更加困难的情况。

## 学习长期依赖性的挑战

理论上，RNN 可以利用任意长序列中的信息。然而，在实践中，它们仅限于回顾几步。更具体地说，RNN 努力从远离当前观测的时间步长中获得有用的上下文信息（Hochreiter 等人，2001）。

基本问题是在多个时间步的反向传播过程中，重复乘法对梯度的影响。因此，**梯度要么消失**并朝零方向减小（典型情况），**要么爆炸**并朝无穷大方向增大（频率较低，但渲染优化非常困难）。

即使参数允许稳定且网络能够存储记忆，长期交互也会由于许多雅可比矩阵（包含梯度信息的矩阵）的乘法而获得指数级更小的权重。实验表明，对于只有 10 或 20 个元素的序列，随机梯度下降在训练 RNN 时面临着严峻的挑战。

为了应对这一挑战，引入了几种 RNN 设计技术，包括**回声状态网络**（Jaeger，2001）和**泄漏单元**（Hihi 和 Bengio，1996）。后者在不同的时间尺度上运行，将模型的一部分集中在较高频率上，其他部分集中在较低频率的表示上，以便有意识地学习并结合数据的不同方面。其他策略包括跳过时间步的连接或集成不同频率信号的单元。

最成功的方法是使用经过培训的门控单元来调节单元在当前状态下保留多少过去的信息以及何时重置或忘记这些信息。因此，他们能够通过数百个时间步学习依赖关系。最流行的例子包括**长短期记忆**（**LSTM**单元）和**选通循环单元**（**GRUs**）。Chung 等人（2014 年）进行的一项实证比较发现，这两个单元都优于简单的重复单元，如 tanh 单元，同时在各种语音和音乐建模任务中表现同样出色。

### 长-短期记忆——学会遗忘多少

具有 LSTM 体系结构的 RNN 具有维护内部状态的更复杂单元。它们包含门来跟踪输入序列元素之间的依赖关系，并相应地调节单元的状态。这些门反复地相互连接，而不是我们前面遇到的隐藏单元。他们的目标是通过让梯度不变地通过，解决由于可能非常小或非常大的值的重复乘法而导致梯度消失和爆炸的问题（Hochreiter 和 Schmidhuber，1996）。

*图 19.3*中的图表显示了展开的 LSTM 单元的信息流，并概述了其典型的选通机制：

![](img/B15439_19_03.png)

图 19.3：通过展开的 LSTM 单元的信息流

一个典型的 LSTM 单元将**四个参数化层**组合在一起，这些层通过转换和传递向量相互作用，并与细胞状态相互作用。这些层通常包括一个输入门、一个输出门和一个遗忘门，但也有一些变体可能有额外的门或缺少这些机制。*图 19.4*中的白色节点标识元素操作，灰色元素表示在训练过程中学习到的权重和偏差参数的层：

![](img/B15439_19_04.png)

图 19.4:LSTM 单元的逻辑和数学

**单元状态**、*c*沿单元顶部的水平连接传递。细胞状态与各种门的相互作用导致一系列反复的决定：

1.  **忘记门**控制单元状态的无效程度，以调节网络的内存。它接收先前的隐藏状态*h*<sub style="font-style: italic;">t-1</sub>和当前输入*x*<sub style="font-style: italic;">t</sub>作为输入，计算乙状结肠激活，并将结果值*f*<sub style="font-style: italic;">t</sub>乘以单元状态，该值已被归一化为[0，1]范围，相应地减少或保持它。
2.  **输入门**还从*h*<sub style="font-style: italic;">t-1</sub>和*x*<sub style="font-style: italic;">t</sub>计算生成更新候选项的乙状结肠激活。在[-1，1]范围内的一个*tan*<sub style="font-style: italic;">h</sub>激活乘以更新候选者、*u*<sub style="font-style: italic;">t</sub>，并根据得到的符号，将结果与单元状态相加或相减。
3.  **输出门**使用乙状激活*o*<sub xmlns:epub="http://www.idpf.org/2007/ops" style="font-style: italic;">t</sub>过滤更新的单元状态，并将其乘以使用*tan*h 激活归一化到范围[-1,1]的单元状态。

## 门控经常单位

GRU 通过省略输出门简化了 LSTM 单元。它们在某些语言建模任务上表现出类似的性能，但在较小的数据集上表现更好。

GRU 的目标是让每个经常性单元自适应地捕获不同时间尺度的依赖关系。与 LSTM 单元类似，GRU 具有门控单元，用于调节单元内的信息流，但丢弃单独的存储单元（更多详细信息，请参阅 GitHub 上的参考资料）。

# 具有张量流 2 的时间序列的 RNN

在本节中，我们将说明如何使用 TensorFlow 2 库为各种场景构建递归神经网络。第一组模型包括单变量和多变量时间序列的回归和分类。第二组任务侧重于使用转换为单词嵌入的文本数据进行情绪分析的文本数据（参见*第 16 章*、*盈利电话和 SEC 文件的单词嵌入*。

更具体地说，我们将首先演示如何准备时间序列数据以预测**单变量时间序列**的下一个值，并使用单个 LSTM 层预测股票指数值。

接下来，我们将构建一个具有三个不同输入的**深度 RNN**，以对资产价格变动进行分类。为此，我们将结合两层**堆叠的 LSTM**和学习的**嵌入**以及一个热编码的分类数据。最后，我们将演示如何使用 RNN 对**多元时间序列**建模。

## 单变量回归——预测标准普尔 500 指数

在本小节中，我们将预测 S&P500 指数值（具体实施请参见`univariate_time_series_regression`笔记本）。

我们将从联邦储备银行的数据服务获取 2010-2019 年的数据（FRED；参见*第 2 章*、*市场和基础数据–来源和技术*：

```py
sp500 = web.DataReader('SP500', 'fred', start='2010', end='2020').dropna()
sp500.info()
DatetimeIndex: 2463 entries, 2010-03-22 to 2019-12-31
Data columns (total 1 columns):
 #   Column  Non-Null Count  Dtype
---  ------  --------------  -----  
 0   SP500   2463 non-null   float64 
```

我们通过使用 scikit learn 的`MinMaxScaler()`类将数据缩放到[0,1]间隔来预处理数据：

```py
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
sp500_scaled = pd.Series(scaler.fit_transform(sp500).squeeze(), 
                         index=sp500.index) 
```

## 如何为 RNN 生成时间序列数据

我们生成了 63 个连续交易日（约三个月）的序列，并使用一个包含 20 个隐藏单位的 LSTM 层提前一个时间步预测标度指数值。

每个 LSTM 层的输入必须有三个维度，即：

*   **批量**：一个序列就是一个样本。批次包含一个或多个样本。
*   **时间步**：一个时间步是样本中的单个观察。
*   **特征**：一个特征是一个时间步长上的一次观察。

下图显示了输入张量的形状：

![](img/B15439_19_05.png)

图 19.5:RNN 输入张量的三维

我们的标准普尔 500 指数样本有 2463 个观测值或时间步长。我们将使用 63 个观测值的窗口创建重叠序列。使用一个大小为*T*=5 的简单窗口来说明这种自回归序列模式，我们获得了输入-输出对，其中每个输出都与其前五个滞后相关联，如下表所示：

![](img/B15439_19_06.png)

图 19.6:T=5 大小窗口的输入输出对

我们可以使用`create_univariate_rnn_data()`函数来堆叠使用滚动窗口选择的重叠序列：

```py
def create_univariate_rnn_data(data, window_size):
    y = data[window_size:]
    data = data.values.reshape(-1, 1) # make 2D
    n = data.shape[0]
    X = np.hstack(tuple([data[i: n-j, :] for i, j in enumerate(range(
                                                     window_size, 0, -1))]))
    return pd.DataFrame(X, index=y.index), y 
```

我们使用`window_size=63`将此函数应用于重新缩放的股票指数，以获得二维数据集，其形状为样本数 x 时间步数：

```py
X, y = create_univariate_rnn_data(sp500_scaled, window_size=63)
X.shape
(2356, 63) 
```

我们将使用 2019 年的数据作为我们的测试集，并重塑特征，以添加必要的三维度：

```py
X_train = X[:'2018'].values.reshape(-1, window_size, 1)
y_train = y[:'2018']
# keep the last year for testing
X_test = X['2019'].values.reshape(-1, window_size, 1)
y_test = y['2019'] 
```

### 如何使用单个 LSTM 层定义两层 RNN

现在，我们已经从时间序列中创建了自回归输入/输出对，并将这些对拆分为训练集和测试集，我们可以定义我们的 RNN 架构。TensorFlow 2 的 Keras 接口使得构建具有两个隐藏层的 RNN 非常简单，具有以下规格：

*   **第 1 层**：一个包含 10 个隐藏单元的 LSTM 模块（带`input_shape = (window_size,1)`；我们将在训练时在省略的第一维度中定义`batch_size`）
*   **第二层**：一个完全连接的模块，具有单个单元和线性激活
*   **损失**：`mean_squared_error`匹配回归目标

只需几行代码即可创建计算图：

```py
rnn = Sequential([
    LSTM(units=10,
         input_shape=(window_size, n_features), name='LSTM'),
    Dense(1, name='Output')
]) 
```

总结显示，该模型有 491 个参数：

```py
rnn.summary()
Layer (type)                 Output Shape              Param #   
LSTM (LSTM)                  (None, 10)                480       
Output (Dense)               (None, 1)                 11        
Total params: 491
Trainable params: 491 
```

### 培训和评估模型

我们使用为 RNN 推荐的带有默认设置的 RMSProp 优化器对模型进行训练，并为这个回归问题编译带有`mean_squared_error`的模型：

```py
optimizer = keras.optimizers.RMSprop(lr=0.001,
                                     rho=0.9,
                                     epsilon=1e-08,
                                     decay=0.0)
rnn.compile(loss='mean_squared_error', optimizer=optimizer) 
```

我们定义了一个`EarlyStopping`回调，并对模型进行 500 集的训练：

```py
early_stopping = EarlyStopping(monitor='val_loss', 
                              patience=50,
                              restore_best_weights=True)
lstm_training = rnn.fit(X_train,
                       y_train,
                       epochs=500,
                       batch_size=20,
                       validation_data=(X_test, y_test),
                       callbacks=[checkpointer, early_stopping],
                       verbose=1) 
```

训练在 138 个时代后停止。*图 19.7*中的损失历史显示了培训和验证 RMSE 的 5 个历元滚动平均值，突出显示了最佳历元，并显示损失为 0.998%：

```py
loss_history = pd.DataFrame(lstm_training.history).pow(.5)
loss_history.index += 1
best_rmse = loss_history.val_loss.min()
best_epoch = loss_history.val_loss.idxmin()
loss_history.columns=['Training RMSE', 'Validation RMSE']
title = f'Best Validation RMSE: {best_rmse:.4%}'
loss_history.rolling(5).mean().plot(logy=True, lw=2, title=title, ax=ax) 
```

![](img/B15439_19_07.png)

图 19.7：交叉验证性能

### 重新调整预测

我们使用`MinMaxScaler()`的`inverse_transform()`方法将模型预测重新缩放到原始 S&P 500 值范围：

```py
test_predict_scaled = rnn.predict(X_test)
test_predict = (pd.Series(scaler.inverse_transform(test_predict_scaled)
                          .squeeze(), 
                          index=y_test.index)) 
```

*图 19.8*中的四个曲线图说明了基于重标度预测的预测性能，该预测跟踪 2019 年样本 S&P500 数据，测试**信息系数**（**IC**为 0.9889：

![](img/B15439_19_08.png)

图 19.8:RNN 在标准普尔 500 指数预测中的表现

## 叠加 LSTM–预测价格变动和回报

我们现在将通过使用`Quandl`股价数据叠加两个 LSTM 层来构建一个更深层次的模型（有关实现细节，请参见`stacked_lstm_with_feature_embeddings.ipynb`笔记本）。此外，我们将包括本质上不连续的特征，即识别权益和月份的指标变量。

*图 19.9*概述了说明如何在单个深度神经网络中组合不同数据源的架构。例如，您可以添加技术或基本功能来代替或补充一个热编码月份：

![](img/B15439_19_09.png)

图 19.9：具有附加功能的堆叠 LSTM 体系结构

### 准备数据–如何创建每周股票回报

我们加载 Quandl 调整后的股价数据（参见 GitHub 上关于如何获取源数据的说明）如下（参考`build_dataset.ipynb`笔记本）：

```py
prices = (pd.read_hdf('../data/assets.h5', 'quandl/wiki/prices')
          .adj_close
          .unstack().loc['2007':])
prices.info()
DatetimeIndex: 2896 entries, 2007-01-01 to 2018-03-27
Columns: 3199 entries, A to ZUMZ 
```

我们首先为近 2500 只股票生成每周回报，并提供 2008-17 年期间的完整数据：

```py
returns = (prices
           .resample('W')
           .last()
           .pct_change()
           .loc['2008': '2017']
           .dropna(axis=1)
           .sort_index(ascending=False))
returns.info()
DatetimeIndex: 2576 entries, 2017-12-29 to 2008-01-01
Columns: 2489 entries, A to ZUMZ 
```

我们为每台股票和每周创建并叠加 52 周收益的滚动序列，如下所示：

```py
n = len(returns)
T = 52
tcols = list(range(T))
tickers = returns.columns
data = pd.DataFrame()
for i in range(n-T-1):
    df = returns.iloc[i:i+T+1]
    date = df.index.max()    
    data = pd.concat([data, (df.reset_index(drop=True).T
                             .assign(date=date, ticker=tickers)
                             .set_index(['ticker', 'date']))]) 
```

我们在 1%和 99%的水平上对异常值进行排序，并创建一个二元标签，表明每周收益率是否为正：

```py
data[tcols] = (data[tcols].apply(lambda x: x.clip(lower=x.quantile(.01),
                                                  upper=x.quantile(.99))))
data['label'] = (data['fwd_returns'] > 0).astype(int) 
```

因此，我们对 2400 多只股票进行了 116 万次观察，每只股票都有 52 周的滞后回报（加上标签）：

```py
data.shape
(1167341, 53) 
```

现在，我们准备创建附加功能，将数据拆分为训练集和测试集，并将它们转换为 LSTM 所需的三维格式。

### 如何以 RNN 格式创建多个输入

此示例说明了如何组合多个输入数据源，即：

*   52 周滞后收益滚动序列
*   12 个月内每个月一个热编码指标变量
*   股票代码的整数编码值

以下代码生成两个附加功能：

```py
data['month'] = data.index.get_level_values('date').month
data = pd.get_dummies(data, columns=['month'], prefix='month')
data['ticker'] = pd.factorize(data.index.get_level_values('ticker'))[0] 
```

接下来，我们创建了一个涵盖 2009-2016 年的培训集和一个单独的测试集，其中包含 2017 年的数据，最后一整年的数据：

```py
train_data = data[:'2016']
test_data = data['2017'] 
```

对于培训和测试数据集，我们生成一个包含三个输入数组的列表，如图 19.9 所示：

*   滞后返回序列（使用*图 19.5*中描述的格式）
*   整数编码的股票代码作为一维数组
*   月模拟为每月一列的二维数组

```py
window_size=52
sequence = list(range(1, window_size+1))
X_train = [
    train_data.loc[:, sequence].values.reshape(-1, window_size , 1),
    train_data.ticker,
    train_data.filter(like='month')
]
y_train = train_data.label
[x.shape for x in X_train], y_train.shape
[(1035424, 52, 1), (1035424,), (1035424, 12)], (1035424,) 
```

### 如何使用 Keras 的功能 API 定义架构

Keras 的功能 API使得设计一个类似于本节开头所述的架构的架构变得简单，该架构具有多个输入（或多个输出，如*第 18 章*、*CNN 中针对金融时间序列和卫星图像的 SVHN 示例*。此示例说明了具有三个输入的网络：

1.  **两个堆叠的 LSTM 层**，分别为 25 和 10 个单元
2.  一个**嵌入层**，学习股票的 10 维实值表示
3.  月份的**一个热编码**表示

我们首先定义三个输入及其各自的形状：

```py
n_features = 1
returns = Input(shape=(window_size, n_features), name='Returns')
tickers = Input(shape=(1,), name='Tickers')
months = Input(shape=(12,), name='Months') 
```

为了定义**堆叠 LSTM 层**，我们将第一层的`return_sequences`关键字设置为`True`。这确保第一层以预期的三维输入格式生成输出。请注意，我们还使用了衰减正则化以及函数 API 如何将张量输出从一层传递到下一层的输入：

```py
lstm1 = LSTM(units=lstm1_units,
             input_shape=(window_size, n_features),
             name='LSTM1',
             dropout=.2,
             return_sequences=True)(returns)
lstm_model = LSTM(units=lstm2_units,
             dropout=.2,
             name='LSTM2')(lstm1) 
```

RNNs 的 TensorFlow 2 指南强调了一个事实，即 GPU 支持仅在大多数 LSTM 设置（[使用默认值时可用 https://www.tensorflow.org/guide/keras/rnn](https://www.tensorflow.org/guide/keras/rnn) ）。

**嵌入层**要求：

*   `input_dim`关键字，定义层将学习多少嵌入
*   `output_dim`关键字，定义嵌入的大小
*   `input_length`参数，设置传递到层的元素数量（这里，每个样本只有一个标记器）

嵌入层的目标是学习向量表示法，这些向量表示法可以捕获特征值相对于结果的相对位置。我们将为大约 2500 个 ticker 值选择一个五维嵌入，以将嵌入层与 LSTM 层以及我们需要重塑（或展平）它的月份假人结合起来：

```py
ticker_embedding = Embedding(input_dim=n_tickers,
                             output_dim=5,
                             input_length=1)(tickers)
ticker_embedding = Reshape(target_shape=(5,))(ticker_embedding) 
```

现在我们可以将三个张量连接起来，后跟`BatchNormalization`：

```py
merged = concatenate([lstm_model, ticker_embedding, months], name='Merged')
bn = BatchNormalization()(merged) 
```

完全连接的最终层学习从这些堆叠的 LSTM 层、股票代码嵌入和月份指标到反映下周正或负回报的二进制结果的映射。我们通过使用我们刚刚定义的隐式数据流定义其输入和输出来制定完整的 RNN：

```py
hidden_dense = Dense(10, name='FC1')(bn)
output = Dense(1, name='Output', activation='sigmoid')(hidden_dense)
rnn = Model(inputs=[returns, tickers, months], outputs=output) 
```

摘要列出了这个稍微复杂的架构，包含 16984 个参数：

```py
Layer (type)                    Output Shape         Param #     Connected to
Returns (InputLayer)            [(None, 52, 1)]      0
Tickers (InputLayer)            [(None, 1)]          0
LSTM1 (LSTM)                    (None, 52, 25)       2700        Returns[0][0]
embedding (Embedding)           (None, 1, 5)         12445       Tickers[0][0]
LSTM2 (LSTM)                    (None, 10)           1440        LSTM1[0][0]
reshape (Reshape)               (None, 5)           0          embedding[0][0]
Months (InputLayer)             [(None, 12)]         0
Merged (Concatenate)            (None, 27)           0           LSTM2[0][0]
                                                                 reshape[0][0]
                                                                 Months[0][0]
batch_normalization (BatchNorma (None, 27)           108         Merged[0][0]
FC1 (Dense)                     (None, 10)           280         
atch_normalization[0][0]
Output (Dense)                  (None, 1)            11          FC1[0][0]
Total params: 16,984
Trainable params: 16,930
Non-trainable params: 54 
```

我们使用推荐的带有默认设置的 RMSProp 优化器编译模型，并计算用于提前停止的 AUC 度量：

```py
optimizer = tf.keras.optimizers.RMSprop(lr=0.001,
                                        rho=0.9,
                                        epsilon=1e-08,
                                        decay=0.0)
rnn.compile(loss='binary_crossentropy',
            optimizer=optimizer,
            metrics=['accuracy', 
                     tf.keras.metrics.AUC(name='AUC')]) 
```

我们使用提前停车对模型进行 50 个阶段的训练：

```py
result = rnn.fit(X_train,
                 y_train,
                 epochs=50,
                 batch_size=32,
                 validation_data=(X_test, y_test),
                 callbacks=[early_stopping]) 
```

以下图表显示训练在 8 个阶段后停止，每个阶段在单个 GPU 上大约需要 3 分钟。最佳模型的测试 AUC 为 0.6816，测试精度为 0.6193：

![](img/B15439_19_10.png)

图 19.10：堆叠 LSTM 分类交叉验证性能

测试预测和实际每周回报的 IC 为 0.32。

### 预测回报而不是定向价格变动

`stacked_lstm_with_feature_embeddings_regression.ipynb`笔记本说明了如何使模型适应预测回报的回归任务，而不是二元价格变化。

所需的变更很小；只需执行以下操作：

1.  选择`fwd_returns`结果而不是二进制`label`。
2.  将模型输出转换为线性（默认），而不是`sigmoid`。
3.  将损失更新为均方误差（和提前停止参考）。
4.  删除或更新可选指标以匹配回归任务。

使用其他相同的训练参数（除了默认设置的 Adam 优化器在这种情况下产生更好的结果），验证损失在九个时期内得到改善。每周平均 IC 为 3.32，整个期间为 6.68，但在 1%的水平上显著。预测收益最高和最低五分位股票之间的每周平均收益差略高于 20 个基点：

![](img/B15439_19_11.png)

图 19.11：叠加 LSTM 回归样本外性能

## 宏观数据的多元时间序列回归

到目前为止，我们的建模工作仅限于单个时间序列。RNN 非常适合于多元时间序列，代表了我们在*第 9 章**波动预测和统计套利*中介绍的**向量自回归**（**VAR**模型）的非线性替代方案。具体实施请参见`multivariate_timeseries`笔记本。

### 装载情绪和工业生产数据

我们将展示如何使用 RNN 对多个时间序列进行建模和预测，该 RNN 使用的数据集与我们在 VAR 示例中使用的数据集相同。40 多年来，美联储弗雷德服务中心每月对消费者情绪和工业生产进行观察：

```py
df = web.DataReader(['UMCSENT', 'IPGMFN'], 'fred', '1980', '2019-12').dropna()
df.columns = ['sentiment', 'ip']
df.info()
DatetimeIndex: 480 entries, 1980-01-01 to 2019-12-01
Data columns (total 2 columns):
sentiment    480 non-null float64
ip           480 non-null float64 
```

### 使数据稳定并调整比例

我们对这两个序列采用相同的变换年差，对工业生产进行先验对数变换，以实现平稳性（详见*第 9 章**时间序列波动预测模型和统计套利*时间序列模型）。我们还将其重新缩放到[0,1]范围，以确保网络在训练期间为两个系列提供相等的权重：

```py
df_transformed = (pd.DataFrame({'ip': np.log(df.ip).diff(12),
                               'sentiment': df.sentiment.diff(12)}).dropna())
df_transformed = df_transformed.apply(minmax_scale) 
```

*图 19.12*显示原始和转换后的宏时间序列：

![](img/B15439_19_12.png)

图 19.12：原始和转换的时间序列

### 创建多变量 RNN 输入

`create_multivariate_rnn_data()`函数将多个时间序列的数据集转换为 TensorFlow 的 RNN 层所需的三维形状，形成`n_samples × window_size × n_series`：

```py
def create_multivariate_rnn_data(data, window_size):
    y = data[window_size:]
    n = data.shape[0]
    X = np.stack([data[i: j] for i, j in enumerate(range(window_size, n))],
                 axis=0)
    return X, y 
```

`window_size`值为 18 确保第二维度中的条目是相应输出变量的滞后 18 个月。因此，我们获得两个特征的 RNN 模型输入，如下所示：

```py
X, y = create_multivariate_rnn_data(df_transformed, window_size=window_size)
X.shape, y.shape
((450, 18, 2), (450, 2)) 
```

最后，我们将数据分为培训和测试集，使用过去 24 个月来测试样本外性能：

```py
test_size = 24
train_size = X.shape[0]-test_size
X_train, y_train = X[:train_size], y[:train_size]
X_test, y_test = X[train_size:], y[train_size:]
X_train.shape, X_test.shape
((426, 18, 2), (24, 18, 2)) 
```

### 定义和培训模型

考虑到相对较小的数据集，我们使用了比前面的示例更简单的 RNN 体系结构。它有一个包含 12 个单元的单一 LSTM 层，然后是一个包含 6 个单元的完全连接层。输出层有两个单元，每个时间序列一个。

我们使用平均绝对损失和推荐的 RMSProp 优化器进行编译：

```py
n_features = output_size = 2
lstm_units = 12
dense_units = 6
rnn = Sequential([
    LSTM(units=lstm_units,
         dropout=.1,
         recurrent_dropout=.1,
         input_shape=(window_size, n_features), name='LSTM',
         return_sequences=False),
    Dense(dense_units, name='FC'),
    Dense(output_size, name='Output')
])
rnn.compile(loss='mae', optimizer='RMSProp') 
```

模型仍有 812 个参数，而*第 9 章**中的和`VAR(1, 1)`模型*中的【参数为 10 个，用于波动预测和统计套利的时间序列模型：

```py
Layer (type)                 Output Shape              Param #   
LSTM (LSTM)                  (None, 12)                720       
FC (Dense)                   (None, 6)                 78        
Output (Dense)               (None, 2)                 14        
Total params: 812
Trainable params: 812 
```

我们使用提前停车的方式，以 20 的`batch_size`进行 100 个时代的训练：

```py
result = rnn.fit(X_train,
                y_train,
                epochs=100,
                batch_size=20,
                shuffle=False,
                validation_data=(X_test, y_test),
                callbacks=[checkpointer, early_stopping],
                verbose=1) 
```

训练在 62 个时期后提前停止，测试 MAE 为 0.034，比同一任务中 VAR 模型 0.043 的测试 MAE 提高了近 25%。

然而，这两个结果并不完全具有可比性，因为 RNN 产生 18 个 1 步预测，而 VAR 模型使用自己的预测作为样本外预测的输入。您可能需要调整 VAR 设置，以获得可比较的预测并比较性能。

*图 19.13*突出显示了培训和验证错误，以及两个系列的样本外预测：

![](img/B15439_19_13.png)

图 19.13：具有多个宏系列的 RNN 交叉验证和测试结果

# 文本数据的 RNN

RNN 通常应用于各种自然语言处理任务，从机器翻译到情感分析，我们已经在本书第 3 部分中遇到过。在本节中，我们将说明如何将 RNN 应用于文本数据，以检测积极或消极情绪（易于扩展到更细粒度的情绪量表）并预测股票回报。

更具体地说，我们将使用单词嵌入来表示文档中的标记。我们在*第 16 章*、*盈利电话和 SEC 文件*中介绍了单词嵌入。它们是将标记转换为密集的实值向量的优秀技术，因为单词在嵌入空间中的相对位置编码了它们在培训文档中使用方式的有用语义方面。

我们在前面的堆叠 RNN 示例中看到，TensorFlow 有一个内置的嵌入层，允许我们训练特定于手头任务的向量表示。或者，我们可以使用预训练向量。我们将在以下三个部分中演示这两种方法。

## 用于情感分类的嵌入 LSTM

此示例演示如何在分类任务上训练 RNN 时学习自定义嵌入向量。这与 word2vec 模型不同，word2vec 模型在优化相邻标记预测的同时学习向量，从而使其能够捕获单词之间的某些语义关系（参见*第 16 章*、*盈利电话和 SEC 文件的单词嵌入*。以预测情绪为目标学习单词向量意味着嵌入将反映标记与其关联的结果之间的关系。

### 加载 IMDB 电影回顾数据

为了保持数据的可管理性，我们将用 IMDB 评论数据集来说明这个用例，该数据集包含 50000 个正面和负面的电影评论，平均分为一个训练集和一个测试集，每个数据集中都有平衡的标签。词汇表由 88586 个标记组成。或者，您可以使用更大的 Yelp review 数据（在将文本转换为数字序列后；请参阅下一节使用预训练嵌入或 TensorFlow 2 文档）。

数据集被捆绑到 TensorFlow 中，并且可以加载，以便每个审查都表示为一个整数编码序列。我们可以将词汇量限制在`num_words`，同时使用`skip_top`过滤掉频繁且可能信息量较小的单词以及长于`maxlen`的句子。我们还可以选择`oov_char`值，该值表示我们根据频率选择从词汇表中排除的标记：

```py
from tensorflow.keras.datasets import imdb
vocab_size = 20000
(X_train, y_train), (X_test, y_test) = imdb.load_data(seed=42, 
                                                      skip_top=0,
                                                      maxlen=None, 
                                                      oov_char=2, 
                                                      index_from=3,
                                                      num_words=vocab_size) 
```

在第二步中，将整数列表转换为固定大小的数组，我们可以对这些数组进行堆栈，并将其作为输入提供给 RNN。`pad_sequence`函数生成等长、截断和填充的数组，以符合`maxlen`：

```py
maxlen = 100
X_train_padded = pad_sequences(X_train, 
                        truncating='pre', 
                        padding='pre', 
                        maxlen=maxlen) 
```

### 定义嵌入和 RNN 体系结构

现在，我们可以设置 RNN 体系结构。第一层学习单词 embedings。我们像以前一样使用以下方法定义嵌入维度：

*   `input_dim`关键字，设置需要嵌入的令牌数量
*   `output_dim`关键字，定义每个嵌入的大小
*   `input_len`参数，指定每个输入序列的长度

请注意，这次我们使用的 GRU 单元训练速度更快，在较小的数据量上表现更好。我们还在使用经常性辍学进行正规化：

```py
embedding_size = 100
rnn = Sequential([
    Embedding(input_dim=vocab_size, 
              output_dim= embedding_size, 
              input_length=maxlen),
    GRU(units=32,
        dropout=0.2, # comment out to use optimized GPU implementation
        recurrent_dropout=0.2),
    Dense(1, activation='sigmoid')
]) 
```

由此产生的模型具有 200 多万个可训练参数：

```py
Layer (type)                 Output Shape              Param #   
embedding (Embedding)        (None, 100, 100)          2000000   
gru (GRU)                    (None, 32)                12864     
dense (Dense)                (None, 1)                 33        
Total params: 2,012,897
Trainable params: 2,012,897 
```

我们编译模型以使用 AUC 度量，并提前停车：

```py
rnn.fit(X_train_padded, 
       y_train, 
       batch_size=32, 
       epochs=25, 
       validation_data=(X_test_padded, y_test),
       callbacks=[early_stopping],
       verbose=1) 
```

训练在 12 个历次后停止，我们恢复最佳模型的权重，发现高测试 AUC 为 0.9393：

```py
y_score = rnn.predict(X_test_padded)
roc_auc_score(y_score=y_score.squeeze(), y_true=y_test)
0.9393289376 
```

*图 19.14*显示了交叉验证在准确性和 AUC 方面的表现：

![](img/B15439_19_14.png)

图 19.14：使用 IMDB 数据和自定义嵌入对 RNN 进行交叉验证

## 基于预训练词向量的情感分析

在*第 16 章*、*盈利电话和 SEC 文件的单词嵌入*中，我们讨论了如何学习特定领域的单词嵌入。Word2vec 和相关学习算法生成高质量的 word向量，但需要大量数据集。因此，研究小组共享在大型数据集上训练的词向量是很常见的，类似于我们在前一章转移学习一节中遇到的预训练深度学习模型的权重。

我们现在将用 IMDB review 数据集（参考 GitHub 和实现细节请参考`sentiment_analysis_pretrained_embeddings`笔记本）来说明如何使用斯坦福 NLP 集团提供的（**手套**的预训练**全局向量进行单词表示。**

### 文本数据的预处理

我们将从源代码加载 IMDB 数据集，以手动预处理它（参见笔记本）。TensorFlow提供了一个`Tokenizer`，我们将使用它将文本文档转换为整数编码序列：

```py
num_words = 10000
t = Tokenizer(num_words=num_words,
              lower=True, 
              oov_token=2)
t.fit_on_texts(train_data.review)
vocab_size = len(t.word_index) + 1
train_data_encoded = t.texts_to_sequences(train_data.review)
test_data_encoded = t.texts_to_sequences(test_data.review) 
```

我们还使用`pad_sequences`函数将列表（长度不等）转换为训练和测试数据的填充和截断数组的堆叠集：

```py
max_length = 100
X_train_padded = pad_sequences(train_data_encoded, 
                               maxlen=max_length, 
                               padding='post',
                               truncating='post')
y_train = train_data['label']
X_train_padded.shape
(25000, 100) 
```

### 加载预训练手套嵌入件

我们下载手套数据并将其解压缩到代码中指定的位置，现在将创建一个字典，将手套标记映射到 100 维实值向量：

```py
glove_path = Path('data/glove/glove.6B.100d.txt')
embeddings_index = dict()
for line in glove_path.open(encoding='latin1'):
    values = line.split()
    word = values[0]
    coefs = np.asarray(values[1:], dtype='float32')
    embeddings_index[word] = coefs 
```

我们使用大约 340000 个单词向量创建与词汇表匹配的嵌入矩阵，以便 RNN 可以通过令牌索引访问嵌入：

```py
embedding_matrix = np.zeros((vocab_size, 100))
for word, i in t.word_index.items():
    embedding_vector = embeddings_index.get(word)
    if embedding_vector is not None:
        embedding_matrix[i] = embedding_vector 
```

### 使用冻结权重定义体系结构

与上例中 RNN 设置的不同之处在于，我们将把嵌入矩阵传递给嵌入层，并将其设置为*不可训练*，以便在训练期间权重保持不变：

```py
rnn = Sequential([
    Embedding(input_dim=vocab_size,
              output_dim=embedding_size,
              input_length=max_length,
              weights=[embedding_matrix],
              trainable=False),
    GRU(units=32,  dropout=0.2, recurrent_dropout=0.2),
    Dense(1, activation='sigmoid')]) 
```

从现在开始，我们照旧进行。如*图 19.15*所示，培训持续 32 个阶段，我们获得的测试 AUC 分数为 0.9106。这比前几节中的结果稍差，我们在那里学习了该领域的自定义嵌入，强调了培训自己的单词嵌入的价值：

![](img/B15439_19_15.png)

图 19.15：具有多个宏系列的 RNN 交叉验证和测试结果

您可能希望将这些技术应用于我们在第 3 部分中使用的更大的金融文本数据集。

## 预测美国证券交易委员会备案嵌入的收益

在*第 16 章*、*盈利通知和 SEC 备案的词语嵌入*中，我们讨论了产品评论和财务文本数据之间的重要差异。虽然前者有助于说明重要的工作流程，但在本节中，我们将处理更具挑战性但也更相关的财务文档。更具体地说，我们将使用*第 16 章*、*盈利通知和 SEC 备案*中介绍的 SEC 备案数据，学习专门用于预测从发布前到发布后一周与披露相关联的股票行情的回报的词语嵌入。

`sec_filings_return_prediction`笔记本包含本节的代码示例。参见*第 16 章*中的`sec_preprocessing`笔记本、*收入电话和 SEC 文件的单词嵌入*，以及 GitHub 数据文件夹中关于如何获取数据的说明。

### 使用 yfinance 获取股票价格数据

2013-2016 年期间有 22631 份申请。我们使用 yfinance 获取相关 6630 个股票报价器的股价数据，因为它比 Quandl 的 WIKI 数据覆盖率更高。我们使用备案索引中的股票代码和备案日期（参见*第 16 章*、*盈利电话和 SEC 备案的文字嵌入*）下载备案数据之前三个月和之后一个月的每日调整股票价格，如下所示：，捕获过程中的价格数据和失败的报价器：

```py
yf_data, missing = [], []
for i, (symbol, dates) in enumerate(filing_index.groupby('ticker').date_filed, 
                                    1):
    ticker = yf.Ticker(symbol)
    for idx, date in dates.to_dict().items():
        start = date - timedelta(days=93)
        end = date + timedelta(days=31)
        df = ticker.history(start=start, end=end)
        if df.empty:
            missing.append(symbol)
        else:
            yf_data.append(df.assign(ticker=symbol, filing=idx)) 
```

我们使用 Quandl Wiki 数据（见笔记本）获得了 3954 个股票的数据和几百个缺失股票的源价格，最终得到了 16758 份 4762 个符号的文件。

### 预处理 SEC 归档数据

与产品评论相比，财务文本文档往往更长，结构更正式。此外，在这种情况下，我们依赖于来自 EDGAR 的数据，这些数据需要对 XBRL 来源进行解析（参见*第 2 章*、*市场和基础数据–来源和技术*），并且可能存在错误，例如包括所需章节以外的材料。我们在预处理过程中采取了几个步骤来处理异常值，并按照我们将在下一节中构建的模型的要求，将文本数据格式化为等长的整数序列：

1.  删除所有包含少于 5 个或多于 50 个标记的句子；这大约影响到。5%的句子。
2.  创建包含 4 个元素的 28599 个大图、10032 个三角形和 2372 个 n-gram。
3.  将文件转换为表示令牌频率等级的整数序列，删除令牌少于 100 个的文件，并截断 20000 个元素的序列。

*图 19.16*突出显示了剩余 16538 份文件的一些语料库统计数据，其中 179214369 个标记，其中约 204206 个是唯一的。左侧面板以对数刻度显示令牌频率分布；最常见的术语“百万”、“业务”、“公司”和“产品”每次出现的次数超过 100 万次。和往常一样，有一条很长的尾巴，60%的代币出现的次数少于 25 次。

中央面板显示了句子长度的分布，模式约为 10 个标记。最后，右面板显示了归档长度的分布，由于截断，峰值为 20000：

![](img/B15439_19_16.png)

图 19.16：具有多个宏系列的 RNN 交叉验证和测试结果

### 为 RNN 模型准备数据

现在我们需要我们的模型预测结果。假设申报发生在市场时间之后，我们将计算（有点武断地）申报日（或前一天，如果该日期没有价格）的五天远期收益。显然，这一假设可能是错误的，强调了需要*第 2 章*、*市场和基础数据——来源和技术*以及*第 3 章*、*金融替代数据——类别和用例*中强调的**时间点数据**。我们将忽略这个问题，因为它是使用免费数据的隐藏成本。

我们按如下方式计算远期收益，剔除周收益低于 50%或高于 100%的异常值：

```py
fwd_return = {}
for filing in filings:
    date_filed = filing_index.at[filing, 'date_filed']
    price_data = prices[prices.filing==filing].close.sort_index()

    try:
        r = (price_data
             .pct_change(periods=5)
             .shift(-5)
             .loc[:date_filed]
             .iloc[-1])
    except:
        continue
    if not np.isnan(r) and -.5 < r < 1:
        fwd_return[filing] = r 
```

这给我们留下了 16355 个数据点。现在，我们将这些结果与其匹配的归档顺序相结合，并将申报表转换为 NumPy 数组：

```py
y, X = [], []
for filing_id, fwd_ret in fwd_return.items():
    X.append(np.load(vector_path / f'{filing_id}.npy') + 2)
    y.append(fwd_ret)
y = np.array(y) 
```

最后，我们创建一个 90:10 的训练/测试分割，并使用本节第一个示例中介绍的`pad_sequences`函数生成每个 20000 个元素的固定长度序列：

```py
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1)
X_train = pad_sequences(X_train, 
                        truncating='pre', 
                        padding='pre', 
                        maxlen=maxlen)
X_test = pad_sequences(X_test, 
                       truncating='pre', 
                       padding='pre', 
                       maxlen=maxlen)
X_train.shape, X_test.shape
((14719, 20000), (1636, 20000)) 
```

### 建立、培训和评估 RNN 模型

现在我们可以定义我们的 RNN 架构。第一层学习单词 embedings。我们如前所述定义嵌入维度，设置如下：

*   `input_dim`关键字与词汇表的大小有关
*   `output_dim`关键字与每个嵌入的大小有关
*   `input_length`参数表示每个输入序列的长度

对于递归层，我们使用一个双向 GRU 单元，该单元向前和向后扫描文本，并连接结果输出。在线性输出之前，我们还添加了一个五个单位的密集层，用于正则化的批量标准化和退出：

```py
embedding_size = 100
input_dim = X_train.max() + 1
rnn = Sequential([
    Embedding(input_dim=input_dim, 
              output_dim=embedding_size, 
              input_length=maxlen,
             name='EMB'),
    BatchNormalization(name='BN1'),
    Bidirectional(GRU(32), name='BD1'),
    BatchNormalization(name='BN2'),
    Dropout(.1, name='DO1'),
    Dense(5, name='D'),
    Dense(1, activation='linear', name='OUT')]) 
```

由此产生的模型具有 250 多万个可训练参数：

```py
rnn.summary()
Layer (type)                 Output Shape              Param #   
EMB (Embedding)              (None, 20000, 100)        2500000   
BN1 (BatchNormalization)     (None, 20000, 100)        400       
BD1 (Bidirectional)          (None, 64)                25728     
BN2 (BatchNormalization)     (None, 64)                256       
DO1 (Dropout)                (None, 64)                0         
D (Dense)                    (None, 5)                 325       
OUT (Dense)                  (None, 1)                 6         
Total params: 2,526,715
Trainable params: 2,526,387
Non-trainable params: 328 
```

我们使用 Adam 优化器进行编译，针对此回归任务的均方损失，同时跟踪损失的平方根和平均绝对误差作为可选指标：

```py
rnn.compile(loss='mse', 
            optimizer='Adam',
            metrics=[RootMeanSquaredError(name='RMSE'),
                     MeanAbsoluteError(name='MAE')]) 
```

通过提前停车，我们可以分批次进行多达 100 个时代的训练，每个批次进行 32 次观察：

```py
early_stopping = EarlyStopping(monitor='val_MAE', 
                               patience=5,
                               restore_best_weights=True)
training = rnn.fit(X_train,
                   y_train,
                   batch_size=32,
                   epochs=100,
                   validation_data=(X_test, y_test),
                   callbacks=[early_stopping],
                   verbose=1) 
```

平均绝对误差仅在 4 个时期内得到改善，如图 19.17 的左侧面板所示：

![](img/B15439_19_17.png)

图 19.17：使用 SEC 文件预测每周收益的 RNN 交叉验证测试结果

在测试集上，最佳模型实现了 6.02 的高度显著 IC：

```py
y_score = rnn.predict(X_test)
rho, p = spearmanr(y_score.squeeze(), y_test)
print(f'{rho*100:.2f} ({p:.2%})')
6.02 (1.48%) 
```

### 经验教训和下一步

该模型能够生成比仅使用文本数据的偶然性好得多的回报预测。有两个警告建议我们对实验结果持保留态度，也有理由相信我们可以改进这个实验的结果。

一方面，股票价格数据和经解析的 SEC 文件的质量都远远不够完美。目前尚不清楚价格数据是否会对结果产生正面或负面的影响，但它们肯定会增加误差幅度。对 SEC 文件进行更仔细的解析和清理，很可能会通过消除噪音来改善结果。

另一方面，有许多优化可以很好地改善结果。从文本输入开始，除了选择某些部分之外，我们没有尝试解析归档内容；删除样板语言或尝试选择最有意义的语句可能会有价值。我们还对文件的最大长度和我们可以重新访问的词汇表的大小做了一些随意的选择。我们还可以缩短或延长每周的预测时间。此外，我们可以对模型体系结构的多个方面进行改进，从嵌入的大小到层的数量和大小以及正则化的程度。

最基本的是，我们可以将文本输入与一组更丰富的互补功能结合起来，如前一节所示，使用具有多个输入的堆叠 LSTM。最后，我们当然希望有更多的文件。

# 总结

在本章中，我们介绍了专门针对顺序数据定制的 RNN 体系结构。我们介绍了 RNN 的工作原理，分析了计算图，并了解了 RNN 如何通过多个步骤实现参数共享，以捕获 FFNN 和 CNN 不太适合的长程依赖关系。

我们还回顾了消失和爆炸梯度的挑战，并了解了门控单元（如长-短期记忆单元）如何使 RNN 在数百个时间步中学习依赖性。最后，我们将 RNN 应用于算法交易中常见的挑战，如预测单变量和多变量时间序列以及使用 SEC 文件进行情绪分析。

在下一章中，我们将介绍无监督的深度学习技术，如自动编码器和生成性对抗网络，以及它们在投资和交易策略中的应用。